{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU\n",
    "\n",
    "Rectified Linear Unit (ReLU) is the goto activation function for hidden layers in present days replacing sigmoid function which was generally used. It replaces negative activations with zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z_values):\n",
    "    return np.maximum(0,Z_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU Derivative\n",
    "\n",
    "Modifies activation values to 0 or 1. Value is modified to 1 if activation value is greater than 0 else modified to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_derivative(x):\n",
    "    return (x > 0).astype(int)\n",
    "# def ReLU_derivative(x, epsilon=1e-8):\n",
    "#     return (x > epsilon).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, Layers, Weights=None, Biases=None):\n",
    "    # Initialize weights and biases if unspecified\n",
    "    if Weights is None:\n",
    "        Weights=[]\n",
    "        Weights.append(np.random.rand(X.shape[1], Layers[0]))\n",
    "        for i in range(1, len(Layers)):\n",
    "            Weights.append(np.random.rand(Weights[i-1].shape[1], Layers[i]))\n",
    "#         Weights = []\n",
    "#         Weights.append(np.random.randn(X.shape[1], Layers[0]) * np.sqrt(2 / X.shape[1]))\n",
    "#         for i in range(1, len(Layers)):\n",
    "#             Weights.append(np.random.randn(Layers[i-1], Layers[i]) * np.sqrt(2 / Layers[i-1]))\n",
    "\n",
    "\n",
    "    if Biases is None:\n",
    "        Biases=[]\n",
    "        Biases = [np.random.rand(n_units) for n_units in Layers]\n",
    "    \n",
    "    Z_values = []\n",
    "    Activations = []\n",
    "    \n",
    "    print(\"Starting forward propagation...\")\n",
    "    \n",
    "    # First layer\n",
    "    dot_product = np.dot(X, Weights[0]) \n",
    "    L1_value = dot_product + Biases[0][np.newaxis, :]\n",
    "    Z_values.append(L1_value)\n",
    "    Activations.append(ReLU(L1_value))\n",
    "#     print(f\"Layer 1 Activation Shape: {Activations[-1].shape} Weights Shape : {Weights[0].shape}\")\n",
    "    \n",
    "    # Remaining layers\n",
    "    for i in range(len(Layers) - 1):  \n",
    "        dot_product = np.dot(Activations[i], Weights[i+1])\n",
    "        Z_value = dot_product + Biases[i+1]\n",
    "        Z_values.append(Z_value)\n",
    "        Activations.append(ReLU(Z_value))\n",
    "#         print(f\"Layer {i + 2} Activation Shape: {Activations[-1].shape}\")\n",
    "    y_cap=[Activations[-1]]\n",
    "    \n",
    "    return Activations, Weights, Biases, y_cap, Z_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting forward propagation...\n",
      "Layer 1 Activation: [[1.10449432 1.28862874 1.22164721 1.17002564]\n",
      " [1.44830937 1.52407879 1.40906453 1.52999429]\n",
      " [1.11243343 1.40599084 1.14447304 1.31340686]\n",
      " [0.50403972 0.74303263 0.81555059 0.50125189]\n",
      " [1.76727958 1.42108344 1.68574913 1.56675887]\n",
      " [1.80321545 2.02537064 1.63361647 2.06177799]\n",
      " [1.40683922 1.06036104 1.43649235 1.14573242]\n",
      " [1.59694618 1.32408546 1.55881968 1.42579799]\n",
      " [1.76383558 1.47452625 1.64950278 1.62616365]\n",
      " [1.19271611 1.25378101 1.28022664 1.18812171]] \n",
      "\n",
      " Weights: [[0.61851958 0.598196   0.45431733 0.68947099]\n",
      " [0.52990721 0.73793115 0.25494646 0.84209881]\n",
      " [0.77537102 0.05739419 0.54365442 0.39499212]]\n",
      "\n",
      " Biases: [0.39941169 0.70159489 0.7435835  0.42328453]\n",
      "\n",
      "\n",
      "Layer 2 Activation: [[2.17022113 3.7428614 ]\n",
      " [2.50832826 4.48983531]\n",
      " [2.25944854 3.80420279]\n",
      " [1.49590397 2.32808028]\n",
      " [2.59853128 5.0136395 ]\n",
      " [3.02791711 5.43370822]\n",
      " [2.17193287 4.1416699 ]\n",
      " [2.44687904 4.64490156]\n",
      " [2.63524298 5.03017149]\n",
      " [2.19232362 3.87790865]] \n",
      "\n",
      " Weights: [[0.20280577 0.98194764]\n",
      " [0.39755347 0.19509793]\n",
      " [0.18874461 0.75159542]\n",
      " [0.38726002 0.61829748]]\n",
      "\n",
      " Biases: [0.75024101 0.76528868]\n",
      "\n",
      "\n",
      "Layer 3 Activation: [[3.67267404]\n",
      " [4.37985014]\n",
      " [3.74004386]\n",
      " [2.32813746]\n",
      " [4.85352853]\n",
      " [5.28740462]\n",
      " [4.02318915]\n",
      " [4.50674342]\n",
      " [4.87360079]\n",
      " [3.79462334]] \n",
      "\n",
      " Weights: [[0.15125781]\n",
      " [0.87825659]]\n",
      "\n",
      " Biases: [0.05721845]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activation_values,W,B,_,_=forward_propagation(np.random.rand(10,3),Layers=[4,2,1])\n",
    "for i in range(len(activation_values)):\n",
    "    print(f\"Layer {i+1} Activation: {activation_values[i]} \\n\\n Weights: {W[i]}\\n\\n Biases: {B[i]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MSE as cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(Y, calculated_value):\n",
    "    cost = np.mean((np.array(Y) - calculated_value) ** 2) / 2\n",
    "    print(f\"Cost: {cost}\")\n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Gradients \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(Y, Weights, Biases, Activations):\n",
    "    print(\"Calculating gradients...\")\n",
    "    weight_gradient = []\n",
    "    bias_gradient = []\n",
    "    \n",
    "    # Output layer\n",
    "    activation_gradient = (Activations[-1] - np.array(Y).reshape(-1, 1))/len(Y)\n",
    "    Z_gradient = activation_gradient * ReLU_derivative(Activations[-1])\n",
    "    W_gradient = np.dot(Z_gradient.T, Activations[-2])\n",
    "    weight_gradient.insert(0, W_gradient.T)\n",
    "    bias_gradient.insert(0, np.sum(Z_gradient, axis=0))\n",
    "#     print(f\"Output Layer Gradients - W: {W_gradient.shape}, B: {bias_gradient[-1].shape}\")\n",
    "    \n",
    "    # Hidden layers\n",
    "    for i in range(1, len(Weights)):\n",
    "        activation_gradient = np.dot(Z_gradient, Weights[-i].T)\n",
    "        Z_gradient = activation_gradient * ReLU_derivative(Activations[-i-1])\n",
    "        W_gradient = np.dot(Z_gradient.T, Activations[-i-2])\n",
    "        weight_gradient.insert(0, W_gradient.T)\n",
    "        bias_gradient.insert(0, np.sum(Z_gradient, axis=0))\n",
    "#         print(f\"Layer {len(Weights) - i} Gradients - W: {W_gradient.shape}, B: {bias_gradient[-1].shape}\")\n",
    "    \n",
    "    for i in range(len(weight_gradient)):\n",
    "        print(f\"Layer: {i+1} \\n\")\n",
    "        print(f\" weight : {Weights[i]}\\n weight_grad :{weight_gradient[i]} \\n\\n\")\n",
    "        print(f\" bias : {Biases[i]} \\n bias_grad :{bias_gradient[i]}\\n\\n\\n\")\n",
    "\n",
    "    return weight_gradient, bias_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, W, b, Activations, learning_rate):\n",
    "    print(\"Performing backward propagation...\")\n",
    "    new_activation = Activations.copy()\n",
    "    new_activation.insert(0, X)\n",
    "    \n",
    "    weight_gradient, bias_gradient = calculate_gradients(Y, W, b, new_activation)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    new_weights = []\n",
    "    new_biases = []\n",
    "    for i in range(len(W)):\n",
    "        new_weights.append(W[i] - learning_rate * weight_gradient[i])\n",
    "        new_biases.append(b[i] - learning_rate * bias_gradient[i])\n",
    "#         print(f\"Updated Layer {i + 1} Weights Shape: {new_weights[-1].shape}, Biases Shape: {new_biases[-1].shape}\")\n",
    "    \n",
    "    return new_weights, new_biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(X, y, Layers, iterations, learning_rate, error_margin):\n",
    "    print(\"Training MLP...\")\n",
    "    iteration_count = 0\n",
    "    cost = 100\n",
    "    cost_history = []\n",
    " \n",
    "    \n",
    "    while iteration_count < iterations:\n",
    "#     while iteration_count < 20: #Using fixed custom iterations for testing\n",
    "        print(f\"\\nIteration {iteration_count + 1}\")\n",
    "        activation, weight, bias, _,_ = forward_propagation(X, Layers)\n",
    "        cost = calculate_cost(y, activation[-1])\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        W, B = backward_propagation(X, y, weight, bias, activation, learning_rate)\n",
    "        \n",
    "        if cost <= error_margin:\n",
    "            print(\"Error margin reached, stopping training.\")\n",
    "            break\n",
    "        \n",
    "        iteration_count += 1\n",
    "    \n",
    "    return W, B, Layers, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP...\n",
      "\n",
      "Iteration 1\n",
      "Starting forward propagation...\n",
      "Cost: 1.524595466451232\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.87533084 0.36721894 0.19273747 0.53941453 0.54407559 0.19676391\n",
      "  0.62437185 0.05326348]\n",
      " [0.18316749 0.39001111 0.92098501 0.66200418 0.29096609 0.22672928\n",
      "  0.7596117  0.68204326]\n",
      " [0.26386737 0.80120415 0.97850866 0.27418367 0.56193486 0.11489391\n",
      "  0.14975626 0.38689401]]\n",
      " weight_grad :[[0.12972549 0.09288223 0.12197789 0.14913842 0.16010251 0.07744432\n",
      "  0.15833989 0.0962496 ]\n",
      " [0.13209223 0.0945768  0.12420328 0.15185934 0.16302346 0.07885723\n",
      "  0.16122867 0.09800559]\n",
      " [0.12862989 0.0920978  0.12094772 0.14787887 0.15875036 0.07679027\n",
      "  0.15700263 0.09543672]] \n",
      "\n",
      "\n",
      " bias : [0.84483304 0.49753656 0.06905085 0.16262187 0.04855502 0.83131414\n",
      " 0.90609893 0.07790877] \n",
      " bias_grad :[0.22513517 0.16119467 0.21168941 0.2588258  0.27785369 0.13440258\n",
      " 0.2747947  0.16703864]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.48535526 0.23083652 0.65778394 0.51960507]\n",
      " [0.45622695 0.34139566 0.06051526 0.97797165]\n",
      " [0.06381254 0.52903057 0.74027157 0.5711613 ]\n",
      " [0.23587652 0.74410288 0.73101425 0.4704481 ]\n",
      " [0.64399711 0.07363173 0.86184865 0.91476719]\n",
      " [0.10970723 0.892523   0.04490813 0.03820155]\n",
      " [0.30420881 0.73508957 0.8503221  0.18415278]\n",
      " [0.39462738 0.07080179 0.43439051 0.75647515]]\n",
      " weight_grad :[[0.24667852 0.1964821  0.24706948 0.06599298]\n",
      " [0.2141891  0.17060393 0.21452858 0.05730121]\n",
      " [0.196359   0.15640206 0.19667022 0.05253119]\n",
      " [0.15630074 0.12449522 0.15654846 0.04181455]\n",
      " [0.13102992 0.10436674 0.13123759 0.03505394]\n",
      " [0.17546143 0.13975692 0.17573953 0.04694054]\n",
      " [0.27578654 0.21966695 0.27622364 0.07378014]\n",
      " [0.1119989  0.08920833 0.11217641 0.02996265]] \n",
      "\n",
      "\n",
      " bias : [0.06716763 0.39053056 0.84766687 0.43782085] \n",
      " bias_grad :[0.15346078 0.12223316 0.153704   0.04105479]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.98145072 0.55548201]\n",
      " [0.89988969 0.23530778]\n",
      " [0.89595967 0.70896703]\n",
      " [0.27979787 0.11839235]]\n",
      " weight_grad :[[0.39195677 0.22357438]\n",
      " [0.60624576 0.34580604]\n",
      " [0.74627528 0.42567968]\n",
      " [0.6567004  0.37458566]] \n",
      "\n",
      "\n",
      " bias : [0.09920422 0.69318319] \n",
      " bias_grad :[0.11820125 0.06742267]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.07320534]\n",
      " [0.04175674]]\n",
      " weight_grad :[[24.511089  ]\n",
      " [14.33156786]] \n",
      "\n",
      "\n",
      " bias : [0.75170032] \n",
      " bias_grad :[1.61465339]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "Starting forward propagation...\n",
      "Cost: 102.91018695277324\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.56597074 0.96509236 0.97520486 0.39375693 0.32422194 0.11398997\n",
      "  0.10705846 0.15406504]\n",
      " [0.17898394 0.03844726 0.69361822 0.43670034 0.72327766 0.48936119\n",
      "  0.58082037 0.90649413]\n",
      " [0.4262633  0.67948589 0.34481397 0.94272423 0.06187446 0.8563117\n",
      "  0.00560923 0.08312019]]\n",
      " weight_grad :[[ 8.92204768  8.34109874  9.27249753 14.30955064 12.24630581  7.86261736\n",
      "  11.29271442  3.9319751 ]\n",
      " [ 9.02584988  8.43814198  9.38037699 14.47603292 12.38878358  7.95409378\n",
      "  11.42409778  3.97772106]\n",
      " [ 8.90738357  8.32738946  9.25725742 14.28603173 12.22617801  7.84969451\n",
      "  11.27415392  3.92551258]] \n",
      "\n",
      "\n",
      " bias : [0.35203054 0.93696322 0.57083419 0.45858726 0.39084179 0.44336931\n",
      " 0.02078566 0.32413275] \n",
      " bias_grad :[15.43422502 14.42924309 16.04046722 24.75405113 21.18484974 13.60151951\n",
      " 19.5352347   6.80191259]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.3016793  0.3971646  0.29527172 0.95179661]\n",
      " [0.34680429 0.43946691 0.5532293  0.404407  ]\n",
      " [0.30053561 0.37832852 0.9730578  0.27767874]\n",
      " [0.28916815 0.71925688 0.99769765 0.93189805]\n",
      " [0.8819812  0.7125467  0.44411877 0.62316483]\n",
      " [0.04356244 0.35286939 0.7332629  0.45495496]\n",
      " [0.14587248 0.63288788 0.97129055 0.47823514]\n",
      " [0.09707925 0.02752405 0.63531853 0.09839786]]\n",
      " weight_grad :[[ 5.68085591 11.9052308   8.51309455  7.29094879]\n",
      " [10.53282812 22.07339032 15.78405845 13.51808807]\n",
      " [ 9.59350548 20.10487484 14.37642859 12.31253853]\n",
      " [ 8.19494613 17.1739482  12.28060567 10.5175934 ]\n",
      " [ 5.71984366 11.98693648  8.57151998  7.34098662]\n",
      " [ 7.11370245 14.90801227 10.66029883  9.12989894]\n",
      " [ 2.34747635  4.91954878  3.51783049  3.01280831]\n",
      " [ 5.46794591 11.45904052  8.19403648  7.01769492]] \n",
      "\n",
      "\n",
      " bias : [0.8899701  0.77357243 0.91268394 0.98759629] \n",
      " bias_grad :[ 5.51606811 11.55988904  8.2661504   7.07945612]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.31991633 0.45709337]\n",
      " [0.66656463 0.96179004]\n",
      " [0.19955237 0.96444105]\n",
      " [0.99591583 0.00215607]]\n",
      " weight_grad :[[27.97681979 28.01696575]\n",
      " [37.1598833  37.21320669]\n",
      " [56.01440764 56.09478675]\n",
      " [43.56176073 43.62427064]] \n",
      "\n",
      "\n",
      " bias : [0.37540012 0.98173083] \n",
      " bias_grad :[7.09311044 7.10328885]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.51339303]\n",
      " [0.51412973]]\n",
      " weight_grad :[[177.14326125]\n",
      " [213.49737996]] \n",
      "\n",
      "\n",
      " bias : [0.85182823] \n",
      " bias_grad :[13.81614099]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3\n",
      "Starting forward propagation...\n",
      "Cost: 0.5494086991972018\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.70887971 0.40994775 0.2539299  0.43884517 0.89184234 0.93484537\n",
      "  0.75466839 0.43112013]\n",
      " [0.70354643 0.85451985 0.07229546 0.55275383 0.43137033 0.72157364\n",
      "  0.9192885  0.90555538]\n",
      " [0.91621702 0.63963889 0.3927746  0.00743369 0.1079498  0.99859261\n",
      "  0.1096334  0.51618625]]\n",
      " weight_grad :[[0.0460514  0.05990135 0.04374664 0.04354056 0.03380901 0.03278991\n",
      "  0.04774586 0.05382937]\n",
      " [0.04747429 0.06175217 0.04509832 0.04488587 0.03485364 0.03380305\n",
      "  0.0492211  0.05549259]\n",
      " [0.04438753 0.05773707 0.04216605 0.04196741 0.03258747 0.03160519\n",
      "  0.04602076 0.05188448]] \n",
      "\n",
      "\n",
      " bias : [0.0267249  0.92654627 0.36453099 0.39453086 0.16613582 0.53217418\n",
      " 0.76195537 0.90854735] \n",
      " bias_grad :[0.07485793 0.09737143 0.07111148 0.07077648 0.05495756 0.05330099\n",
      " 0.07761232 0.08750126]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.83627278 0.64539091 0.06218943 0.24591741]\n",
      " [0.11069843 0.84387091 0.63802825 0.90185218]\n",
      " [0.2677756  0.44466926 0.40161243 0.72753681]\n",
      " [0.40170217 0.14281666 0.81232563 0.2652956 ]\n",
      " [0.0323683  0.18736264 0.42435478 0.87280562]\n",
      " [0.37757378 0.61142394 0.04309323 0.29267678]\n",
      " [0.29350611 0.67936371 0.51723903 0.37542914]\n",
      " [0.90446553 0.60669994 0.02040417 0.70515673]]\n",
      " weight_grad :[[0.06505716 0.06146474 0.06988593 0.04185948]\n",
      " [0.09407063 0.0888761  0.10105288 0.0605275 ]\n",
      " [0.03581458 0.03383692 0.03847287 0.02304404]\n",
      " [0.04566846 0.04314667 0.04905813 0.02938428]\n",
      " [0.0471424  0.04453922 0.05064147 0.03033265]\n",
      " [0.09662705 0.09129136 0.10379905 0.06217237]\n",
      " [0.08395917 0.079323   0.09019092 0.05402152]\n",
      " [0.0920185  0.08693729 0.09884844 0.05920711]] \n",
      "\n",
      "\n",
      " bias : [0.61358523 0.0316861  0.61172511 0.35296636] \n",
      " bias_grad :[0.04479666 0.04232301 0.04812162 0.02882334]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.41180514 0.83594812]\n",
      " [0.27502247 0.91015353]\n",
      " [0.96805599 0.34316419]\n",
      " [0.52024643 0.26843702]]\n",
      " weight_grad :[[0.22105992 0.20944745]\n",
      " [0.27081444 0.25658832]\n",
      " [0.17645504 0.1671857 ]\n",
      " [0.26636019 0.25236805]] \n",
      "\n",
      "\n",
      " bias : [0.79118071 0.48603192] \n",
      " bias_grad :[0.03721147 0.03525672]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.04349463]\n",
      " [0.04120981]]\n",
      " weight_grad :[[11.59559251]\n",
      " [13.36756627]] \n",
      "\n",
      "\n",
      " bias : [0.25874527] \n",
      " bias_grad :[0.85554171]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4\n",
      "Starting forward propagation...\n",
      "Cost: 40.78872132748404\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.96014907 0.3523451  0.13032277 0.25613146 0.91786167 0.59943262\n",
      "  0.26595117 0.02481987]\n",
      " [0.80107556 0.18729903 0.79625004 0.08457668 0.16931338 0.79884522\n",
      "  0.36151232 0.81845295]\n",
      " [0.10051154 0.54039686 0.97512539 0.99373533 0.58626191 0.42611506\n",
      "  0.33611762 0.20028266]]\n",
      " weight_grad :[[3.73939354 4.39564918 2.04648505 4.05375887 5.90558539 4.22602731\n",
      "  3.87834293 3.22728636]\n",
      " [3.69235239 4.34035241 2.02074049 4.00276304 5.83129379 4.17286436\n",
      "  3.82955381 3.18668746]\n",
      " [3.75672935 4.41602739 2.05597254 4.07255207 5.93296365 4.24561915\n",
      "  3.8963229  3.24224804]] \n",
      "\n",
      "\n",
      " bias : [0.14409703 0.86400825 0.399678   0.90214592 0.42764506 0.27370169\n",
      " 0.07431925 0.84393794] \n",
      " bias_grad :[ 6.35544359  7.47081046  3.47818974  6.8897364  10.03708605  7.18252248\n",
      "  6.59160086  5.48507028]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.44063064 0.3837456  0.02143748 0.76292811]\n",
      " [0.64676193 0.12351079 0.9460291  0.88938328]\n",
      " [0.19060854 0.05967908 0.91007492 0.27199352]\n",
      " [0.95368932 0.03431716 0.17204254 0.97294048]\n",
      " [0.64784005 0.9676463  0.72201856 0.17981824]\n",
      " [0.08463829 0.87004385 0.59529881 0.14940019]\n",
      " [0.18618347 0.68117557 0.51391886 0.26528511]\n",
      " [0.63885512 0.46265895 0.14027089 0.05895915]]\n",
      " weight_grad :[[ 4.23540169  7.62541034  2.15207046  3.9361812 ]\n",
      " [ 5.14754627  9.26763395  2.61554465  4.78388505]\n",
      " [ 5.2017555   9.36523217  2.64308917  4.83426454]\n",
      " [ 5.79913589 10.44075485  2.94662701  5.3894415 ]\n",
      " [ 4.84902338  8.73017383  2.46386075  4.50645206]\n",
      " [ 4.60797688  8.2961941   2.34138144  4.28243488]\n",
      " [ 2.19523468  3.95229695  1.11543132  2.04014686]\n",
      " [ 4.98573998  8.97631817  2.53332848  4.63350997]] \n",
      "\n",
      "\n",
      " bias : [0.48974583 0.90463943 0.16583692 0.01358136] \n",
      " bias_grad :[3.43268913 6.18020794 1.74420029 3.19017826]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.58553258 0.25397381]\n",
      " [0.68933024 0.60230922]\n",
      " [0.16996748 0.17975704]\n",
      " [0.68992421 0.17808332]]\n",
      " weight_grad :[[16.76302669 42.16454273]\n",
      " [15.01126919 37.75829467]\n",
      " [15.7904568  39.71820859]\n",
      " [14.17051641 35.64352405]] \n",
      "\n",
      "\n",
      " bias : [0.17739716 0.10501972] \n",
      " bias_grad :[2.80365884 7.05212698]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.3246782 ]\n",
      " [0.81667278]]\n",
      " weight_grad :[[102.01124717]\n",
      " [ 58.38154093]] \n",
      "\n",
      "\n",
      " bias : [0.56114507] \n",
      " bias_grad :[8.63519285]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5\n",
      "Starting forward propagation...\n",
      "Cost: 473.97081109860267\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.2984187  0.03059721 0.87899691 0.08998073 0.91429169 0.51606525\n",
      "  0.23777463 0.04904307]\n",
      " [0.45988525 0.30801544 0.4412692  0.79612288 0.16857498 0.61904208\n",
      "  0.50194919 0.88371791]\n",
      " [0.47401442 0.04522235 0.65355967 0.88503014 0.74454622 0.30347916\n",
      "  0.36876175 0.62006371]]\n",
      " weight_grad :[[37.84807888 27.07017238 49.55058958 46.43129783 47.22511159 57.73450708\n",
      "  35.20941914 39.96187184]\n",
      " [39.11333231 27.97512263 51.20705552 47.98348649 48.80383729 59.66455969\n",
      "  36.38646272 41.29778894]\n",
      " [39.17389825 28.01844135 51.28634826 48.05778762 48.87940871 59.75694865\n",
      "  36.44280618 41.36173745]] \n",
      "\n",
      "\n",
      " bias : [0.99668485 0.20651542 0.50894231 0.2980291  0.44199258 0.69524602\n",
      " 0.05111613 0.16534129] \n",
      " bias_grad :[ 66.18878792  47.34036579  86.65415953  81.19913655  82.58735948\n",
      " 100.96620908  61.57429506  69.88539284]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.14397307 0.56712987 0.4829083  0.59365409]\n",
      " [0.055222   0.2652296  0.3946952  0.72869082]\n",
      " [0.99225772 0.37037674 0.7650275  0.05174642]\n",
      " [0.87750507 0.13844946 0.56332093 0.83549121]\n",
      " [0.49721935 0.6889203  0.30538758 0.73915321]\n",
      " [0.86732127 0.70101155 0.58230599 0.44744887]\n",
      " [0.85698225 0.15976008 0.0427674  0.81992319]\n",
      " [0.03728256 0.74699277 0.21484152 0.9690099 ]]\n",
      " weight_grad :[[65.78158046 87.06160268 64.60305436 40.05229984]\n",
      " [16.55575478 21.91146116 16.25914608 10.08026943]\n",
      " [63.46752417 83.99896041 62.33045612 38.643345  ]\n",
      " [51.4025853  68.03107232 50.48166962 31.2973897 ]\n",
      " [57.57416434 76.19912726 56.54268023 35.05506674]\n",
      " [58.74818588 77.75293907 57.6956683  35.7698909 ]\n",
      " [26.85193111 35.53840058 26.37085872 16.3492818 ]\n",
      " [41.4125904  54.80936253 40.67065294 25.21480141]] \n",
      "\n",
      "\n",
      " bias : [0.85864522 0.90224412 0.58654587 0.9398652 ] \n",
      " bias_grad :[38.25321651 50.62794652 37.56788159 23.29115973]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.59585627 0.82914574]\n",
      " [0.96565593 0.93479018]\n",
      " [0.88830415 0.53593038]\n",
      " [0.3069202  0.55615322]]\n",
      " weight_grad :[[170.44024223 185.60232646]\n",
      " [148.72747753 161.95802985]\n",
      " [133.50100151 145.37703151]\n",
      " [176.33739731 192.02408278]] \n",
      "\n",
      "\n",
      " bias : [0.85544428 0.75569856] \n",
      " bias_grad :[25.52321892 27.79372258]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.86458526]\n",
      " [0.94149734]]\n",
      " weight_grad :[[508.59316213]\n",
      " [542.75098446]] \n",
      "\n",
      "\n",
      " bias : [0.39738959] \n",
      " bias_grad :[29.52076582]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6\n",
      "Starting forward propagation...\n",
      "Cost: 83.4325048371735\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.85760371 0.33175524 0.85044275 0.4193744  0.04306635 0.33406435\n",
      "  0.13944563 0.17868289]\n",
      " [0.2548022  0.44922703 0.7493273  0.32052143 0.53285418 0.81193769\n",
      "  0.99220352 0.90597479]\n",
      " [0.9823076  0.98138223 0.06672258 0.7475545  0.15668801 0.86025686\n",
      "  0.56338459 0.42212623]]\n",
      " weight_grad :[[7.98157431 5.68424731 5.46464841 7.70549141 7.90425488 7.05142173\n",
      "  5.55012692 8.3903609 ]\n",
      " [8.50321323 6.05574352 5.82179265 8.20908682 8.42084056 7.51227017\n",
      "  5.91285764 8.93871623]\n",
      " [8.4750853  6.03571163 5.80253464 8.18193184 8.39298511 7.4874202\n",
      "  5.8932984  8.9091477 ]] \n",
      "\n",
      "\n",
      " bias : [0.50061732 0.37261969 0.71607813 0.15010886 0.76848386 0.61605647\n",
      " 0.19452712 0.86044427] \n",
      " bias_grad :[14.1790304  10.09789703  9.70778608 13.68857731 14.04167473 12.5266419\n",
      "  9.85963612 14.90522769]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.94331479 0.28819813 0.52102732 0.52024621]\n",
      " [0.50684675 0.70135494 0.02571476 0.68653244]\n",
      " [0.11531818 0.86414845 0.23198794 0.44618028]\n",
      " [0.76106739 0.15495312 0.74989842 0.36810752]\n",
      " [0.89415384 0.08587157 0.8434733  0.04931198]\n",
      " [0.6225888  0.44046211 0.49487687 0.41598154]\n",
      " [0.36929649 0.82688249 0.02637891 0.63210033]\n",
      " [0.59321994 0.40864082 0.71709648 0.70789947]]\n",
      " weight_grad :[[11.4018207  11.25265296 15.17196116  4.86609648]\n",
      " [ 9.36429666  9.24178544 12.46070683  3.99651706]\n",
      " [11.14203677 10.99626774 14.82627675  4.75522527]\n",
      " [ 6.78307875  6.69433709  9.02598015  2.89489867]\n",
      " [ 7.97868863  7.87430504 10.61693191  3.40516394]\n",
      " [11.94365554 11.78739909 15.89295979  5.09734206]\n",
      " [ 7.97114903  7.86686408 10.60689924  3.40194616]\n",
      " [11.62235079 11.4702979  15.465412    4.96021484]] \n",
      "\n",
      "\n",
      " bias : [0.55984463 0.20672866 0.93766432 0.85804538] \n",
      " bias_grad :[6.61617647 6.52961835 8.80388974 2.82366772]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.62756356 0.62867099]\n",
      " [0.75811204 0.41393106]\n",
      " [0.92696352 0.69978942]\n",
      " [0.16546443 0.42066134]]\n",
      " weight_grad :[[47.67896569 32.03578267]\n",
      " [37.32226203 25.07705144]\n",
      " [39.27889828 26.39172706]\n",
      " [42.03323539 28.24238266]] \n",
      "\n",
      "\n",
      " bias : [0.12054391 0.54544107] \n",
      " bias_grad :[6.3012923  4.23387605]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.51055202]\n",
      " [0.34304296]]\n",
      " weight_grad :[[200.45113431]\n",
      " [184.17109596]] \n",
      "\n",
      "\n",
      " bias : [0.5887758] \n",
      " bias_grad :[12.34211618]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7\n",
      "Starting forward propagation...\n",
      "Cost: 41.826137792385765\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.87602149 0.27243404 0.33607566 0.46526669 0.82132183 0.27012279\n",
      "  0.08884153 0.08693321]\n",
      " [0.85629763 0.52149767 0.63906036 0.09619887 0.85547074 0.36232677\n",
      "  0.6654932  0.48559687]\n",
      " [0.04166566 0.89879516 0.64012256 0.00901411 0.97789203 0.16197463\n",
      "  0.68834109 0.11132194]]\n",
      " weight_grad :[[3.61583812 4.26150923 5.09199048 3.9894956  3.14285764 3.50638666\n",
      "  3.89722771 3.03946712]\n",
      " [3.79531924 4.47303984 5.34474409 4.18752414 3.2988612  3.68043488\n",
      "  4.0906763  3.19033863]\n",
      " [3.68486237 4.34285896 5.18919361 4.06565275 3.20285296 3.57332154\n",
      "  3.97162352 3.09748878]] \n",
      "\n",
      "\n",
      " bias : [0.9036617  0.61635117 0.98179622 0.42531556 0.88772841 0.15076797\n",
      " 0.74311228 0.02296364] \n",
      " bias_grad :[6.35896129 7.494465   8.95498339 7.01609066 5.52715841 6.16647545\n",
      " 6.85382456 5.34533159]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.59005394 0.54896518 0.25352195 0.50890784]\n",
      " [0.35078013 0.93994616 0.71815524 0.52576692]\n",
      " [0.77851507 0.3643629  0.86558925 0.38181188]\n",
      " [0.60522274 0.13715391 0.47852212 0.58550653]\n",
      " [0.5468377  0.04297199 0.36080742 0.40129974]\n",
      " [0.03881136 0.73925728 0.52854496 0.88185504]\n",
      " [0.34093147 0.19500016 0.81488657 0.52822859]\n",
      " [0.55820653 0.73779191 0.31735728 0.1147433 ]]\n",
      " weight_grad :[[ 9.6813806   2.51570543  7.36317152  6.59659659]\n",
      " [ 8.01370396  2.08235988  6.09482049  5.46029274]\n",
      " [ 9.62262291  2.50043725  7.31848338  6.5565609 ]\n",
      " [ 3.76115529  0.97733569  2.86054569  2.56273616]\n",
      " [12.15539625  3.15857806  9.24478349  8.28231518]\n",
      " [ 3.07123446  0.79805986  2.33582658  2.09264522]\n",
      " [ 7.94551333  2.06464055  6.04295812  5.41382973]\n",
      " [ 2.13284648  0.55421987  1.62213584  1.45325635]] \n",
      "\n",
      "\n",
      " bias : [0.02996798 0.14289862 0.6210472  0.45360873] \n",
      " bias_grad :[4.99811166 1.29875863 3.80131254 3.4055604 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.64430133 0.7370596 ]\n",
      " [0.62121114 0.0463645 ]\n",
      " [0.83497837 0.45022461]\n",
      " [0.42705937 0.5060318 ]]\n",
      " weight_grad :[[ 9.87190097 30.86080822]\n",
      " [ 7.97001957 24.91528694]\n",
      " [11.73610524 36.688546  ]\n",
      " [ 9.94144782 31.07822043]] \n",
      "\n",
      "\n",
      " bias : [0.60543995 0.808962  ] \n",
      " bias_grad :[1.69517004 5.29931548]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.19304613]\n",
      " [0.60348657]]\n",
      " weight_grad :[[136.66603844]\n",
      " [100.13982441]] \n",
      "\n",
      "\n",
      " bias : [0.1112574] \n",
      " bias_grad :[8.7811656]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8\n",
      "Starting forward propagation...\n",
      "Cost: 21.621859595522064\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.98272782 0.48510975 0.35003814 0.71909222 0.57735172 0.87455934\n",
      "  0.14893894 0.57692256]\n",
      " [0.28821393 0.87532985 0.07692164 0.99507537 0.46570281 0.95405561\n",
      "  0.83713843 0.81260417]\n",
      " [0.43240504 0.19893403 0.00671844 0.56308104 0.92473433 0.71782629\n",
      "  0.88363477 0.18414537]]\n",
      " weight_grad :[[2.41758785 1.66590728 2.29722095 1.52805993 1.81623639 1.81489561\n",
      "  2.27147188 2.7745973 ]\n",
      " [2.45755041 1.69344461 2.33519385 1.55331866 1.84625866 1.84489571\n",
      "  2.30901915 2.82046121]\n",
      " [2.33503298 1.60902051 2.21877632 1.47588033 1.75421625 1.75292125\n",
      "  2.19390652 2.67985141]] \n",
      "\n",
      "\n",
      " bias : [0.04103873 0.0362509  0.49104514 0.22291666 0.04332521 0.95021162\n",
      " 0.32190846 0.50676325] \n",
      " bias_grad :[3.99941834 2.75591231 3.80029524 2.52787129 3.00460194 3.00238389\n",
      " 3.75769852 4.59001949]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.37713142 0.44800526 0.83389497 0.98224193]\n",
      " [0.72920481 0.82282043 0.38054527 0.11698249]\n",
      " [0.45551072 0.73338059 0.73305874 0.72752502]\n",
      " [0.18731879 0.30934313 0.63299958 0.42973282]\n",
      " [0.07358699 0.05136975 0.84098843 0.72809068]\n",
      " [0.18646006 0.92622314 0.42041909 0.95878549]\n",
      " [0.33787946 0.37959661 0.9286356  0.63650282]\n",
      " [0.9577883  0.67842244 0.71722806 0.8282737 ]]\n",
      " weight_grad :[[1.61243983 0.75707007 2.63496191 1.13351668]\n",
      " [1.48956272 0.69937702 2.43416279 1.04713624]\n",
      " [1.14170071 0.53604942 1.86570552 0.80259541]\n",
      " [2.41992948 1.13620127 3.9545178  1.70116762]\n",
      " [1.84529824 0.86640137 3.01548653 1.29721202]\n",
      " [3.76243805 1.76653366 6.14837265 2.64492739]\n",
      " [2.18433873 1.02558709 3.56952815 1.53555149]\n",
      " [2.21477578 1.03987785 3.61926672 1.5569482 ]] \n",
      "\n",
      "\n",
      " bias : [0.29165566 0.07524398 0.42186856 0.87325093] \n",
      " bias_grad :[1.51453945 0.71110405 2.47497841 1.06469444]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.20788655 0.67017725]\n",
      " [0.6100837  0.17056071]\n",
      " [0.84653082 0.95266002]\n",
      " [0.10732939 0.48203579]]\n",
      " weight_grad :[[ 2.62648883  9.34085624]\n",
      " [ 3.6889653  13.11945217]\n",
      " [ 4.5034269  16.0160069 ]\n",
      " [ 5.06572944 18.01578209]] \n",
      "\n",
      "\n",
      " bias : [0.39093913 0.41783433] \n",
      " bias_grad :[0.58446913 2.07860856]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.09451097]\n",
      " [0.33611921]]\n",
      " weight_grad :[[78.0975247 ]\n",
      " [99.09659113]] \n",
      "\n",
      "\n",
      " bias : [0.87262716] \n",
      " bias_grad :[6.18414093]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9\n",
      "Starting forward propagation...\n",
      "Cost: 124.97837926917958\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.35264905 0.26148355 0.06294819 0.95458137 0.43342989 0.37337901\n",
      "  0.08308812 0.54227915]\n",
      " [0.93231123 0.40284901 0.70035018 0.40358176 0.2314782  0.37071853\n",
      "  0.35671114 0.19355819]\n",
      " [0.11485735 0.63538749 0.98316852 0.83235287 0.56263454 0.44695018\n",
      "  0.19646117 0.76147222]]\n",
      " weight_grad :[[13.85226429 18.11907852 15.14387855  5.05417708 13.9139816  12.13863099\n",
      "  17.40469013 14.57585437]\n",
      " [14.53293009 19.00940496 15.88801106  5.30252677 14.59768003 12.73509312\n",
      "  18.2599133  15.29207558]\n",
      " [15.02626775 19.6547019  16.42734856  5.48252737 15.0932157  13.16740105\n",
      "  18.87976785 15.81118334]] \n",
      "\n",
      "\n",
      " bias : [0.1369106  0.47922387 0.58567689 0.98399811 0.10339665 0.35242693\n",
      " 0.39647547 0.10693366] \n",
      " bias_grad :[24.34178222 31.83960789 26.61146119  8.88141283 24.45023447 21.33051362\n",
      " 30.58425453 25.61330518]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.06069184 0.11879425 0.3832559  0.83869554]\n",
      " [0.88165213 0.37316833 0.31942169 0.7257911 ]\n",
      " [0.49780153 0.38178449 0.34538364 0.64716651]\n",
      " [0.26426482 0.54580235 0.06639422 0.09397114]\n",
      " [0.68956335 0.82910052 0.517801   0.03735635]\n",
      " [0.34506458 0.07237036 0.25784257 0.64695446]\n",
      " [0.01748448 0.23602782 0.64047349 0.86097353]\n",
      " [0.38888187 0.89554067 0.61654404 0.16195696]]\n",
      " weight_grad :[[11.32306328  4.72185202 21.73573043 16.59032753]\n",
      " [14.79171861  6.16832253 28.39415452 21.67253246]\n",
      " [19.31777049  8.05573998 37.08235498 28.30401382]\n",
      " [26.77300264 11.16466043 51.39340424 39.22727197]\n",
      " [ 9.80312015  4.08801766 18.81805054 14.36333704]\n",
      " [12.46137706  5.1965424  23.92083537 18.25816228]\n",
      " [ 9.12777534  3.80639085 17.52165995 13.37383523]\n",
      " [11.74579789  4.89813738 22.54721097 17.20970988]] \n",
      "\n",
      "\n",
      " bias : [0.31303919 0.67079814 0.46808879 0.23490988] \n",
      " bias_grad :[11.73229231  4.89250539 22.52128569 17.18992178]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.5985942  0.29972439]\n",
      " [0.17641481 0.19170981]\n",
      " [0.9172406  0.78663442]\n",
      " [0.81517926 0.49553867]]\n",
      " weight_grad :[[53.78164098 59.00891117]\n",
      " [62.99612616 69.118992  ]\n",
      " [47.85468711 52.50589104]\n",
      " [60.59115665 66.48027311]] \n",
      "\n",
      "\n",
      " bias : [0.54368113 0.34852968] \n",
      " bias_grad :[12.65005235 13.87956563]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.84408936]\n",
      " [0.92613005]]\n",
      " weight_grad :[[169.97174189]\n",
      " [118.79662677]] \n",
      "\n",
      "\n",
      " bias : [0.24739436] \n",
      " bias_grad :[14.98662697]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10\n",
      "Starting forward propagation...\n",
      "Cost: 30.8264969491168\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.59710799 0.07938616 0.23923559 0.33705379 0.17882905 0.28305706\n",
      "  0.22306718 0.87056867]\n",
      " [0.63176905 0.38837181 0.24927033 0.73269554 0.53445461 0.28672391\n",
      "  0.23425706 0.84655414]\n",
      " [0.01051927 0.81885115 0.43407928 0.50713935 0.76454312 0.0476197\n",
      "  0.82920657 0.20195876]]\n",
      " weight_grad :[[2.20305403 5.88568929 3.45834185 1.68813174 6.02515745 4.7581607\n",
      "  3.36525865 2.37092886]\n",
      " [2.35123797 6.28157818 3.69096016 1.80168047 6.43042739 5.07820867\n",
      "  3.59161591 2.53040456]\n",
      " [2.41834568 6.46086344 3.79630547 1.85310302 6.61396102 5.22314804\n",
      "  3.69412579 2.60262594]] \n",
      "\n",
      "\n",
      " bias : [0.18160026 0.23364279 0.11638289 0.88893926 0.01875583 0.15570461\n",
      " 0.88832809 0.0244402 ] \n",
      " bias_grad :[ 3.87959247 10.36473709  6.09016248  2.97281096 10.61034144  8.37915191\n",
      "  5.92624235  4.17522114]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.46270021 0.04439464 0.28485592 0.36533162]\n",
      " [0.78823972 0.59225732 0.46702021 0.97007384]\n",
      " [0.86837295 0.1269437  0.21114332 0.61954883]\n",
      " [0.4931531  0.3274552  0.05326978 0.06996427]\n",
      " [0.77976824 0.83200106 0.80055346 0.58371571]\n",
      " [0.63572054 0.31526019 0.98441806 0.51027828]\n",
      " [0.59649795 0.34376879 0.24125326 0.49978156]\n",
      " [0.55634564 0.35330572 0.29266316 0.10564763]]\n",
      " weight_grad :[[2.01853767 3.81450361 2.98273948 4.31909638]\n",
      " [2.27229344 4.29403506 3.35770763 4.86206153]\n",
      " [1.49461394 2.824426   2.20855131 3.19804864]\n",
      " [4.08206677 7.71402914 6.03196159 8.7344616 ]\n",
      " [2.04221662 3.85925058 3.01772924 4.36976259]\n",
      " [1.15306979 2.17899767 1.70386059 2.46724132]\n",
      " [3.71243581 7.01552415 5.48576775 7.9435565 ]\n",
      " [2.56775798 4.85238509 3.79430774 5.4942716 ]] \n",
      "\n",
      "\n",
      " bias : [0.46117137 0.75903745 0.35340267 0.30065139] \n",
      " bias_grad :[2.21789332 4.19123319 3.27732203 4.74566075]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.41214682 0.39541829]\n",
      " [0.56317085 0.91096021]\n",
      " [0.28767328 0.82823647]\n",
      " [0.91742158 0.81910024]]\n",
      " weight_grad :[[13.96228197 18.39288165]\n",
      " [ 9.52942477 12.55336215]\n",
      " [ 7.89907748 10.40566273]\n",
      " [ 9.35356953 12.32170341]] \n",
      "\n",
      "\n",
      " bias : [0.10809574 0.83805971] \n",
      " bias_grad :[2.3770569  3.13135965]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.32164723]\n",
      " [0.42371437]]\n",
      " weight_grad :[[69.11818909]\n",
      " [94.50663978]] \n",
      "\n",
      "\n",
      " bias : [0.38193901] \n",
      " bias_grad :[7.39026071]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11\n",
      "Starting forward propagation...\n",
      "Cost: 78.2129161539688\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.22330917 0.52407489 0.93630446 0.03401745 0.98821048 0.31113782\n",
      "  0.88054318 0.27028726]\n",
      " [0.04935509 0.89368466 0.89360186 0.18570595 0.11411888 0.14122579\n",
      "  0.11458895 0.19601937]\n",
      " [0.45767051 0.09356444 0.89150472 0.04018911 0.45371687 0.12091947\n",
      "  0.15893996 0.61830284]]\n",
      " weight_grad :[[ 6.92239233  6.60779007  9.12770306  2.3008982   7.60853304 10.75992575\n",
      "  11.14211988  5.91649777]\n",
      " [ 6.39075694  6.10031594  8.42670119  2.12419066  7.02420247  9.9335702\n",
      "  10.28641206  5.46211446]\n",
      " [ 6.47394304  6.17972148  8.53638842  2.15184046  7.1156339  10.06287178\n",
      "  10.42030645  5.53321277]] \n",
      "\n",
      "\n",
      " bias : [0.83101516 0.56293593 0.2013213  0.5418777  0.53451828 0.71446803\n",
      " 0.61013943 0.88991014] \n",
      " bias_grad :[11.49584903 10.97339669 15.15815507  3.82104583 12.63530626 17.8687477\n",
      " 18.50344822  9.82538434]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.97340156 0.07252717 0.20986539 0.71338145]\n",
      " [0.35828215 0.45910359 0.44489849 0.12248283]\n",
      " [0.92112792 0.37897198 0.40172343 0.54822013]\n",
      " [0.21026618 0.11921791 0.11377702 0.05249566]\n",
      " [0.15413898 0.6524881  0.48519276 0.90212698]\n",
      " [0.92990596 0.15522552 0.86752987 0.9594298 ]\n",
      " [0.81687702 0.44844915 0.87172756 0.28711551]\n",
      " [0.97694073 0.10291886 0.01360192 0.52793958]]\n",
      " weight_grad :[[10.16680491 11.11069408 10.63782742  2.02231913]\n",
      " [11.60860406 12.6863503  12.14642434  2.30911307]\n",
      " [14.33945508 15.67073433 15.00379419  2.85231738]\n",
      " [ 5.59473795  6.11415507  5.8539391   1.11287132]\n",
      " [11.77537149 12.86860046 12.32091801  2.34228543]\n",
      " [ 8.52284624  9.31410981  8.91770505  1.69531285]\n",
      " [10.51571148 11.49199325 11.00289865  2.09172151]\n",
      " [12.27369935 13.41319323 12.84233313  2.44140979]] \n",
      "\n",
      "\n",
      " bias : [0.46804752 0.8468351  0.41610984 0.09552553] \n",
      " bias_grad :[8.12914662 8.88385899 8.50576553 1.61700051]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.27518144 0.89828036]\n",
      " [0.78506065 0.96348515]\n",
      " [0.59832069 0.92823872]\n",
      " [0.02828285 0.17967413]]\n",
      " weight_grad :[[ 2.58639327 68.85901952]\n",
      " [ 1.40705101 37.46071949]\n",
      " [ 1.63364652 43.4935007 ]\n",
      " [ 1.89763841 50.52190706]] \n",
      "\n",
      "\n",
      " bias : [0.62271449 0.46233838] \n",
      " bias_grad :[0.33604553 8.94673147]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.02781802]\n",
      " [0.74061484]]\n",
      " weight_grad :[[109.88287095]\n",
      " [204.6054051 ]] \n",
      "\n",
      "\n",
      " bias : [0.63123269] \n",
      " bias_grad :[12.08014068]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12\n",
      "Starting forward propagation...\n",
      "Cost: 32.155331873288695\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.01527568 0.97596295 0.90661202 0.84137052 0.05302761 0.50568453\n",
      "  0.84167181 0.43565811]\n",
      " [0.31686577 0.53151325 0.7082937  0.28198631 0.00338387 0.76439623\n",
      "  0.93179707 0.70710147]\n",
      " [0.94001699 0.26825984 0.82832365 0.84448802 0.61260836 0.48919672\n",
      "  0.19679468 0.32884732]]\n",
      " weight_grad :[[1.60772054 1.31167369 4.08659951 2.82955242 1.40458981 3.81183882\n",
      "  1.62220869 3.63044512]\n",
      " [1.59898087 1.30454334 4.06438448 2.81417079 1.39695437 3.79111741\n",
      "  1.61339026 3.61070978]\n",
      " [1.59858315 1.30421886 4.06337356 2.81347082 1.39660691 3.79017445\n",
      "  1.61298896 3.60981169]] \n",
      "\n",
      "\n",
      " bias : [0.89766381 0.22880846 0.53283612 0.99619986 0.56456282 0.93466334\n",
      " 0.29370069 0.22519397] \n",
      " bias_grad :[2.72884629 2.2263545  6.93634348 4.80270882 2.38406464 6.46998153\n",
      " 2.75343758 6.16209498]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.76251305 0.21190381 0.07778954 0.0978847 ]\n",
      " [0.20053194 0.04026294 0.19092316 0.64686975]\n",
      " [0.89531899 0.55712578 0.76157205 0.95474054]\n",
      " [0.69703307 0.12121424 0.89822608 0.66339382]\n",
      " [0.65909504 0.03773196 0.28955661 0.13154948]\n",
      " [0.6196456  0.70624302 0.97895183 0.65241335]\n",
      " [0.1324509  0.48295308 0.23198422 0.30808966]\n",
      " [0.73671644 0.67035938 0.45908446 0.83264687]]\n",
      " weight_grad :[[3.81693819 4.88266404 2.66749924 3.38029686]\n",
      " [2.95596387 3.78129741 2.06580012 2.6178143 ]\n",
      " [4.57019084 5.84623208 3.19391617 4.04738065]\n",
      " [4.99904041 6.39482057 3.49362128 4.42717167]\n",
      " [2.2224592  2.84299118 1.55318424 1.96821942]\n",
      " [4.56979042 5.84571985 3.19363633 4.04702603]\n",
      " [3.37054552 4.31163425 2.35553398 2.9849696 ]\n",
      " [2.52952763 3.23579608 1.76778158 2.24016054]] \n",
      "\n",
      "\n",
      " bias : [0.65919606 0.51607898 0.15371922 0.97216348] \n",
      " bias_grad :[2.32314713 2.97179215 1.62355084 2.05738908]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.61885473 0.38560275]\n",
      " [0.92598824 0.23526733]\n",
      " [0.45380392 0.22855291]\n",
      " [0.60719831 0.22792017]]\n",
      " weight_grad :[[23.44601614 12.20861543]\n",
      " [14.53516589  7.56863125]\n",
      " [19.82510776 10.32316599]\n",
      " [22.7444136  11.84328276]] \n",
      "\n",
      "\n",
      " bias : [0.80292544 0.49498767] \n",
      " bias_grad :[2.83434161 1.4758749 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.36985327]\n",
      " [0.19258693]]\n",
      " weight_grad :[[143.44044149]\n",
      " [ 63.75084539]] \n",
      "\n",
      "\n",
      " bias : [0.33442997] \n",
      " bias_grad :[7.66342172]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13\n",
      "Starting forward propagation...\n",
      "Cost: 402.2042157041353\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.15226978 0.82805734 0.19141343 0.91426661 0.85946709 0.34775075\n",
      "  0.96138601 0.49637591]\n",
      " [0.98838756 0.76725212 0.93826561 0.20817331 0.69141951 0.33735896\n",
      "  0.49591852 0.34473871]\n",
      " [0.68247937 0.57958455 0.1302638  0.2500124  0.04314176 0.20799357\n",
      "  0.32339965 0.65091103]]\n",
      " weight_grad :[[38.24496328 46.73320034 59.13891112 35.1811268  20.15248312 25.18335723\n",
      "  32.15667367 31.74286186]\n",
      " [39.17357723 47.8679145  60.57484446 36.0353487  20.64179924 25.79482642\n",
      "  32.93745977 32.51360033]\n",
      " [36.24549837 44.28996634 56.04710065 33.34184072 19.0989017  23.8667593\n",
      "  30.47550744 30.08332991]] \n",
      "\n",
      "\n",
      " bias : [0.52759056 0.96682082 0.63146418 0.31749986 0.63152398 0.86874721\n",
      " 0.39378303 0.43393942] \n",
      " bias_grad :[64.56327238 78.89269811 99.83541097 59.3910538  34.0204342  42.51330927\n",
      " 54.28532028 53.58674347]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.12441674 0.5363385  0.62659857 0.73371841]\n",
      " [0.15902424 0.71923051 0.64599679 0.99835228]\n",
      " [0.70711048 0.99745286 0.8684914  0.52320354]\n",
      " [0.36056401 0.34563791 0.67143675 0.58580574]\n",
      " [0.0161875  0.26079289 0.20455213 0.73766217]\n",
      " [0.24569734 0.39636836 0.26787076 0.54452801]\n",
      " [0.2215771  0.42506491 0.79395906 0.01820744]\n",
      " [0.8301424  0.32593006 0.36715926 0.54909096]]\n",
      " weight_grad :[[27.34457938 68.26046505 64.54851549 31.18793125]\n",
      " [38.40801034 95.87818526 90.66440614 43.80635625]\n",
      " [23.69959272 59.16145931 55.94430641 27.03063221]\n",
      " [19.23176214 48.00838253 45.39772504 21.9348364 ]\n",
      " [27.06690692 67.56730935 63.89305304 30.8712312 ]\n",
      " [23.85215612 59.54230441 56.30444146 27.2046388 ]\n",
      " [24.6982268  61.65435657 58.30164191 28.16962692]\n",
      " [22.25247521 55.54900973 52.52829896 25.38011856]] \n",
      "\n",
      "\n",
      " bias : [0.48660665 0.23647109 0.00447872 0.27637634] \n",
      " bias_grad :[17.08361965 42.64595939 40.32690619 19.48476689]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.70627982 0.10818995]\n",
      " [0.86900392 0.96797997]\n",
      " [0.85340772 0.89062927]\n",
      " [0.63105683 0.25960126]]\n",
      " weight_grad :[[ 84.93406653 108.80924188]\n",
      " [131.23792942 168.12923472]\n",
      " [136.37795842 174.71413853]\n",
      " [156.72949499 200.78654217]] \n",
      "\n",
      "\n",
      " bias : [0.64175588 0.51161732] \n",
      " bias_grad :[20.22011928 25.90404463]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.74606498]\n",
      " [0.95578568]]\n",
      " weight_grad :[[539.23063556]\n",
      " [413.79644751]] \n",
      "\n",
      "\n",
      " bias : [0.73454111] \n",
      " bias_grad :[27.10235678]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14\n",
      "Starting forward propagation...\n",
      "Cost: 220.42967698016633\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.39171584 0.53763089 0.43607607 0.21808222 0.62774764 0.68246421\n",
      "  0.03107012 0.9898929 ]\n",
      " [0.48910926 0.9552762  0.25745799 0.91935983 0.12424004 0.37918527\n",
      "  0.53251163 0.20787116]\n",
      " [0.03225481 0.40300726 0.29254758 0.65551154 0.17021203 0.8154814\n",
      "  0.68632382 0.61846061]]\n",
      " weight_grad :[[17.84130762 17.72226653 24.21992948 29.40889085 18.75942842 19.47209471\n",
      "  14.1638696  23.90610692]\n",
      " [17.79320766 17.67448751 24.15463284 29.32960483 18.70885322 19.41959817\n",
      "  14.12568398 23.84165634]\n",
      " [17.68161627 17.56364068 24.00314531 29.14566209 18.5915193  19.29780675\n",
      "  14.03709373 23.69213167]] \n",
      "\n",
      "\n",
      " bias : [0.78330044 0.44346753 0.59745425 0.78402018 0.46351405 0.45368876\n",
      " 0.26555128 0.75396707] \n",
      " bias_grad :[30.40519304 30.20232298 41.27565351 50.11869213 31.9698564  33.18438375\n",
      " 24.13809564 40.74083647]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.24826868 0.87302783 0.44909394 0.1808271 ]\n",
      " [0.23722484 0.51080727 0.70833385 0.3613211 ]\n",
      " [0.47584212 0.28655582 0.80356636 0.86762308]\n",
      " [0.49512695 0.80736424 0.6364557  0.86557296]\n",
      " [0.25955509 0.55142961 0.01682312 0.74902884]\n",
      " [0.38645564 0.650667   0.02233819 0.64978129]\n",
      " [0.34972056 0.38783983 0.87667409 0.06852418]\n",
      " [0.60293708 0.66642867 0.62201681 0.54387585]]\n",
      " weight_grad :[[14.84773681 27.08052861 15.98083029 30.8199728 ]\n",
      " [17.48574632 31.89194821 18.82015744 36.2957825 ]\n",
      " [13.22557832 24.12190198 14.23487803 27.452801  ]\n",
      " [20.62695649 37.62114673 22.20108662 42.81610361]\n",
      " [11.304228   20.61758459 12.16690136 23.46458614]\n",
      " [17.46259147 31.84971648 18.79523555 36.24771916]\n",
      " [11.20255222 20.4321399  12.05746627 23.25353412]\n",
      " [20.45711705 37.31137954 22.01828602 42.46356189]] \n",
      "\n",
      "\n",
      " bias : [0.28478548 0.52564722 0.66078554 0.19113722] \n",
      " bias_grad :[11.26416825 20.54452032 12.12378449 23.38143271]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.64725101 0.01070929]\n",
      " [0.23590796 0.94941848]\n",
      " [0.23941342 0.46163542]\n",
      " [0.42494765 0.92649342]]\n",
      " weight_grad :[[ 81.26528886  82.55135066]\n",
      " [127.37984565 129.39569223]\n",
      " [111.49573174 113.26020467]\n",
      " [109.69361211 111.42956564]] \n",
      "\n",
      "\n",
      " bias : [0.63611434 0.23491844] \n",
      " bias_grad :[17.11542105 17.38628072]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.84962376]\n",
      " [0.86306946]]\n",
      " weight_grad :[[196.37391321]\n",
      " [328.29659996]] \n",
      "\n",
      "\n",
      " bias : [0.02457209] \n",
      " bias_grad :[20.14470632]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15\n",
      "Starting forward propagation...\n",
      "Cost: 16.78960741521841\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.33959104 0.85100127 0.59046896 0.09808831 0.46119058 0.67982633\n",
      "  0.47144375 0.56198986]\n",
      " [0.82804301 0.74580626 0.52630545 0.32711422 0.2978121  0.49751882\n",
      "  0.04130454 0.50129902]\n",
      " [0.92102    0.19630589 0.74404628 0.95236739 0.68445842 0.42252414\n",
      "  0.77064383 0.49802017]]\n",
      " weight_grad :[[1.28764631 1.07329157 1.7552947  1.26680673 1.93929176 1.38586013\n",
      "  2.04075088 2.22943643]\n",
      " [1.26032773 1.05052072 1.71805454 1.23993028 1.89814794 1.35645786\n",
      "  1.99745451 2.18213693]\n",
      " [1.3473243  1.12303495 1.83664659 1.32551887 2.02917129 1.45009\n",
      "  2.13533268 2.33276317]] \n",
      "\n",
      "\n",
      " bias : [0.87969338 0.2577358  0.37493212 0.84333248 0.57699143 0.43030521\n",
      " 0.15574128 0.55755877] \n",
      " bias_grad :[2.17196553 1.81039799 2.96078166 2.13681391 3.27114273 2.33762984\n",
      " 3.4422811  3.76055059]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.9210181  0.65987634 0.083313   0.56595169]\n",
      " [0.69358778 0.24793479 0.34467865 0.29309196]\n",
      " [0.73113292 0.9785233  0.67045731 0.092356  ]\n",
      " [0.35853015 0.05914975 0.67765778 0.46943604]\n",
      " [0.97972184 0.63780933 0.4302591  0.9785337 ]\n",
      " [0.05687306 0.04961286 0.89143247 0.54650314]\n",
      " [0.87129837 0.90010688 0.88552524 0.10915831]\n",
      " [0.57873258 0.65177101 0.88886096 0.9412325 ]]\n",
      " weight_grad :[[1.94049332 2.01092756 4.08094256 2.08192059]\n",
      " [1.19804055 1.24152592 2.51953181 1.28535628]\n",
      " [1.35739246 1.40666184 2.85465587 1.4563221 ]\n",
      " [1.53038067 1.58592901 3.21845766 1.64191805]\n",
      " [1.31723773 1.36504961 2.77020871 1.4132408 ]\n",
      " [1.25931081 1.30502011 2.64838586 1.35109205]\n",
      " [0.85272866 0.88368022 1.79332576 0.91487733]\n",
      " [1.35613351 1.40535719 2.85200823 1.45497139]] \n",
      "\n",
      "\n",
      " bias : [0.7720985  0.96022004 0.05977001 0.4155948 ] \n",
      " bias_grad :[0.90981662 0.94284031 1.91338426 0.97612599]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.11273914 0.4842114 ]\n",
      " [0.68891277 0.3510359 ]\n",
      " [0.8758625  0.84999431]\n",
      " [0.2570349  0.48364313]]\n",
      " weight_grad :[[ 3.97471274 15.0835508 ]\n",
      " [ 3.29389901 12.49994561]\n",
      " [ 3.19239402 12.11474654]\n",
      " [ 3.08571497 11.70991253]] \n",
      "\n",
      "\n",
      " bias : [0.60867285 0.38127957] \n",
      " bias_grad :[0.46650985 1.77034806]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.08544802]\n",
      " [0.32426484]]\n",
      " weight_grad :[[77.12877481]\n",
      " [87.3589583 ]] \n",
      "\n",
      "\n",
      " bias : [0.209002] \n",
      " bias_grad :[5.4595745]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16\n",
      "Starting forward propagation...\n",
      "Cost: 67.62320527260033\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.14871604 0.49626925 0.08457766 0.14243726 0.97427972 0.51826447\n",
      "  0.95376321 0.49816752]\n",
      " [0.50524247 0.88299988 0.62308626 0.08539725 0.42904058 0.31163101\n",
      "  0.15982994 0.56139645]\n",
      " [0.03050581 0.6958059  0.02678798 0.36078122 0.27745518 0.54695724\n",
      "  0.92524707 0.00175048]]\n",
      " weight_grad :[[ 6.50428092  3.39895597  7.49654599  9.76008987 12.31881216  6.3728174\n",
      "   4.78529295  3.87082012]\n",
      " [ 6.3383863   3.31226406  7.30534321  9.51115438 12.0046153   6.21027582\n",
      "   4.6632419   3.77209311]\n",
      " [ 6.17607441  3.22744439  7.11826972  9.26759501 11.69720397  6.05124455\n",
      "   4.54382671  3.67549824]] \n",
      "\n",
      "\n",
      " bias : [0.87351168 0.87800381 0.87497481 0.48166996 0.01239487 0.93013081\n",
      " 0.55538281 0.5882843 ] \n",
      " bias_grad :[11.04529963  5.77196581 12.73032295 16.57417914 20.91929501 10.82205374\n",
      "  8.12618568  6.57326591]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.2199075  0.77584056 0.06096542 0.71718398]\n",
      " [0.19730799 0.51422155 0.26462574 0.05369679]\n",
      " [0.0440365  0.99297709 0.55707249 0.62483342]\n",
      " [0.75659986 0.72177446 0.87631499 0.29082367]\n",
      " [0.76770218 0.92427115 0.56602049 0.95943126]\n",
      " [0.60213684 0.1761127  0.39383755 0.37585632]\n",
      " [0.42707373 0.19063351 0.55968448 0.07791972]\n",
      " [0.04479697 0.18274781 0.25432809 0.5090507 ]]\n",
      " weight_grad :[[10.23749304  5.49138521  7.36154362  9.82422485]\n",
      " [16.67946534  8.94685535 11.99381638 16.00614695]\n",
      " [10.47355419  5.61800828  7.53128972 10.05075667]\n",
      " [ 6.59006939  3.53490932  4.73876594  6.32404078]\n",
      " [ 7.97206998  4.27621363  5.73253049  7.65025263]\n",
      " [13.88586431  7.44836941  9.98500272 13.3253183 ]\n",
      " [13.93525591  7.47486304 10.02051908 13.37271605]\n",
      " [ 9.72646273  5.21726886  6.99407359  9.33382387]] \n",
      "\n",
      "\n",
      " bias : [0.17738315 0.23387248 0.93635315 0.99990862] \n",
      " bias_grad :[8.07322699 4.33047419 5.80527015 7.74732613]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.634397   0.27787934]\n",
      " [0.0575573  0.50802952]\n",
      " [0.57990167 0.04273208]\n",
      " [0.30350054 0.65427327]]\n",
      " weight_grad :[[39.01525779 30.72885236]\n",
      " [56.03475904 44.13360144]\n",
      " [52.10738312 41.04035635]\n",
      " [51.18722257 40.31562764]] \n",
      "\n",
      "\n",
      " bias : [0.16486404 0.01679496] \n",
      " bias_grad :[9.46164957 7.45210077]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.84133979]\n",
      " [0.66264861]]\n",
      " weight_grad :[[89.48675343]\n",
      " [89.36323044]] \n",
      "\n",
      "\n",
      " bias : [0.54368012] \n",
      " bias_grad :[11.24593137]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17\n",
      "Starting forward propagation...\n",
      "Cost: 73.0794746900715\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.82598336 0.98842393 0.49872212 0.78114298 0.09888376 0.98420741\n",
      "  0.78104319 0.63663167]\n",
      " [0.45140039 0.85139123 0.69438983 0.3038413  0.44878    0.63389314\n",
      "  0.42601219 0.91559121]\n",
      " [0.16921492 0.09044788 0.13087749 0.9502768  0.48493341 0.14917693\n",
      "  0.707901   0.22729724]]\n",
      " weight_grad :[[8.89405271 6.08601246 9.56417303 7.16067174 9.4483562  5.33052202\n",
      "  2.86413242 7.52538507]\n",
      " [8.75102551 5.98814197 9.41036948 7.04551942 9.29641512 5.24480073\n",
      "  2.81807368 7.40436771]\n",
      " [8.10037483 5.54291545 8.71069568 6.52167545 8.60521399 4.85484265\n",
      "  2.60854606 6.85384288]] \n",
      "\n",
      "\n",
      " bias : [0.33382467 0.36246381 0.38096807 0.21483584 0.59960607 0.06953699\n",
      " 0.43146513 0.99271693] \n",
      " bias_grad :[14.47713942  9.90640081 15.56791609 11.65565873 15.37939727  8.67666439\n",
      "  4.66204166 12.2493145 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.09190736 0.96838691 0.65702088 0.75398245]\n",
      " [0.57411529 0.50473384 0.16286454 0.4907822 ]\n",
      " [0.56161889 0.76064527 0.46419382 0.89589206]\n",
      " [0.20218337 0.47786787 0.88424456 0.0236407 ]\n",
      " [0.89615376 0.74829168 0.47978559 0.34090183]\n",
      " [0.35587254 0.204726   0.45151341 0.27942281]\n",
      " [0.16511295 0.46747085 0.0501571  0.20196448]\n",
      " [0.74724647 0.53996861 0.39372781 0.25673222]]\n",
      " weight_grad :[[ 8.11602348  5.65308693 10.87650906  5.48248211]\n",
      " [10.30578779  7.17833239 13.81107318  6.96169711]\n",
      " [ 7.92480255  5.51989503 10.62024856  5.35330982]\n",
      " [ 9.46752947  6.5944569  12.68769986  6.39544243]\n",
      " [ 8.0767881   5.62575815 10.82392863  5.45597809]\n",
      " [ 7.6595838   5.33516113 10.26482153  5.17415101]\n",
      " [10.50687186  7.3183943  14.08055154  7.09753208]\n",
      " [13.86093639  9.65461454 18.57542681  9.3632474 ]] \n",
      "\n",
      "\n",
      " bias : [0.55354084 0.67692308 0.33776895 0.18811078] \n",
      " bias_grad :[6.71406985 4.67657845 8.99771196 4.53544373]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.47414763 0.48765131]\n",
      " [0.29682577 0.40167837]\n",
      " [0.76278789 0.41727468]\n",
      " [0.12899661 0.68422493]]\n",
      " weight_grad :[[52.64154268 28.38178288]\n",
      " [65.34867428 35.23285584]\n",
      " [47.00648173 25.34362958]\n",
      " [41.16055019 22.19178503]] \n",
      "\n",
      "\n",
      " bias : [0.36750566 0.80665146] \n",
      " bias_grad :[9.10918756 4.91123494]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.79456062]\n",
      " [0.42838879]]\n",
      " weight_grad :[[111.84830447]\n",
      " [134.72287974]] \n",
      "\n",
      "\n",
      " bias : [0.44111523] \n",
      " bias_grad :[11.46443374]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18\n",
      "Starting forward propagation...\n",
      "Cost: 14.83844268004285\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.45552076 0.7007583  0.1131316  0.65576658 0.71551477 0.60682798\n",
      "  0.87973057 0.37395475]\n",
      " [0.42037925 0.9231401  0.77034897 0.31567447 0.6023939  0.95416737\n",
      "  0.52449737 0.25331716]\n",
      " [0.36344822 0.90519425 0.57697788 0.48886924 0.44920741 0.58017234\n",
      "  0.32247762 0.13266691]]\n",
      " weight_grad :[[1.43221275 1.62257553 0.99929966 1.70575246 1.30099814 1.94165737\n",
      "  1.61542595 1.43938516]\n",
      " [1.43837604 1.62955802 1.00359998 1.71309288 1.30659677 1.95001297\n",
      "  1.62237767 1.44557931]\n",
      " [1.38542105 1.56956451 0.96665163 1.65002397 1.25849335 1.87822165\n",
      "  1.56264851 1.39235913]] \n",
      "\n",
      "\n",
      " bias : [0.62653646 0.00337896 0.43127399 0.61316594 0.08563103 0.24424949\n",
      " 0.78987335 0.10508728] \n",
      " bias_grad :[2.34079138 2.65191804 1.63324341 2.78786141 2.1263358  3.17342158\n",
      " 2.64023285 2.35251388]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.52483451 0.1856994  0.16159848 0.93474233]\n",
      " [0.3920364  0.58692409 0.93464451 0.39407509]\n",
      " [0.43896939 0.40107647 0.06257407 0.37745571]\n",
      " [0.55516091 0.54374658 0.45284865 0.70195511]\n",
      " [0.03120182 0.43018855 0.83368055 0.49504305]\n",
      " [0.92515799 0.86565275 0.90879661 0.13474351]\n",
      " [0.7262988  0.70502439 0.47177077 0.32497467]\n",
      " [0.59295269 0.41941133 0.74122056 0.33160155]]\n",
      " weight_grad :[[1.39696864 1.94634901 1.23141492 2.06856801]\n",
      " [1.55551182 2.16724184 1.37116926 2.30333158]\n",
      " [1.33280517 1.85695222 1.17485541 1.97355764]\n",
      " [1.51759064 2.11440754 1.33774209 2.2471796 ]\n",
      " [1.17483359 1.63685578 1.03560493 1.73964047]\n",
      " [1.56574332 2.18149704 1.38018824 2.31848192]\n",
      " [1.86572731 2.59945454 1.64462134 2.76268464]\n",
      " [0.57560925 0.80197683 0.50739422 0.85233615]] \n",
      "\n",
      "\n",
      " bias : [0.54947619 0.00959454 0.55503647 0.86208022] \n",
      " bias_grad :[1.01327042 1.41175529 0.89318849 1.50040503]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.38400067 0.26818746]\n",
      " [0.64529203 0.25665431]\n",
      " [0.09138933 0.49857811]\n",
      " [0.64337376 0.31779752]]\n",
      " weight_grad :[[10.22174887  9.63420604]\n",
      " [ 9.35881245  8.82087092]\n",
      " [10.55614442  9.94938065]\n",
      " [ 9.34465788  8.80752996]] \n",
      "\n",
      "\n",
      " bias : [0.04767007 0.74614229] \n",
      " bias_grad :[1.59125894 1.49979389]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.31267985]\n",
      " [0.29470712]]\n",
      " weight_grad :[[54.42310188]\n",
      " [46.57607921]] \n",
      "\n",
      "\n",
      " bias : [0.24132473] \n",
      " bias_grad :[5.08909967]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19\n",
      "Starting forward propagation...\n",
      "Cost: 122.61582842729369\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.37190543 0.87420605 0.04673063 0.63098579 0.42148532 0.98999103\n",
      "  0.55516725 0.43681647]\n",
      " [0.78850468 0.58369017 0.52998489 0.97686782 0.6678306  0.32280703\n",
      "  0.57993255 0.95489236]\n",
      " [0.22304039 0.25475307 0.18066879 0.55151042 0.84186061 0.83634077\n",
      "  0.82784482 0.91047882]]\n",
      " weight_grad :[[ 7.00124042 11.40168211 10.82864283 15.2077274  11.68609704  5.63293378\n",
      "  10.81691602  9.27850001]\n",
      " [ 7.33397465 11.9435475  11.3432745  15.93047524 12.24147926  5.90063918\n",
      "  11.33099038  9.71946109]\n",
      " [ 7.08337443 11.53543925 10.95567744 15.3861346  11.82319075  5.6990157\n",
      "  10.94381306  9.38734936]] \n",
      "\n",
      "\n",
      " bias : [0.00250385 0.22670019 0.68024591 0.09662221 0.85362806 0.45962123\n",
      " 0.85683276 0.59985946] \n",
      " bias_grad :[11.98955792 19.52527263 18.54394829 26.04308915 20.0123305   9.64634575\n",
      " 18.52386624 15.8893434 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[3.48361908e-01 7.09642654e-01 3.52474248e-01 3.40276288e-02]\n",
      " [4.65311223e-01 3.13048016e-01 8.46404496e-01 6.69473786e-01]\n",
      " [5.31862382e-01 2.84011790e-01 6.90453649e-01 5.83345048e-01]\n",
      " [7.68927977e-01 3.16786527e-01 8.90304945e-01 9.21053820e-01]\n",
      " [4.60855419e-01 6.48615050e-01 7.50092309e-01 5.66789323e-01]\n",
      " [3.60054727e-01 7.07515713e-03 6.19289695e-01 3.24343876e-04]\n",
      " [4.35725171e-01 7.75088201e-01 7.48443369e-01 3.12026904e-01]\n",
      " [2.99169822e-01 4.75803283e-01 9.58950350e-01 2.54652649e-01]]\n",
      " weight_grad :[[11.8921862   4.96849097  6.01315726  6.12591647]\n",
      " [17.75379824  7.41744073  8.97701895  9.14535672]\n",
      " [16.2379979   6.78414756  8.21057065  8.36453593]\n",
      " [19.80373559  8.27389345 10.01354793 10.20132278]\n",
      " [28.60648434 11.95163419 14.46456406 14.73580471]\n",
      " [24.66499504 10.30490131 12.47159198 12.70546026]\n",
      " [28.88062313 12.06616789 14.60317942 14.8770194 ]\n",
      " [28.19739071 11.78071709 14.25771022 14.52507193]] \n",
      "\n",
      "\n",
      " bias : [0.42997621 0.59754721 0.51202049 0.47868389] \n",
      " bias_grad :[14.26309592  5.95904421  7.2119825   7.34722217]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.93922453 0.1781401 ]\n",
      " [0.27355664 0.28654557]\n",
      " [0.41394316 0.19888768]\n",
      " [0.00512233 0.94614449]]\n",
      " weight_grad :[[ 82.27331263  46.09605571]\n",
      " [ 84.63231798  47.41775819]\n",
      " [135.46465718  75.89807903]\n",
      " [ 76.26752934  42.73113807]] \n",
      "\n",
      "\n",
      " bias : [0.52368596 0.35763027] \n",
      " bias_grad :[13.72728192  7.69111552]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.92445943]\n",
      " [0.51795573]]\n",
      " weight_grad :[[177.4863883 ]\n",
      " [154.59719604]] \n",
      "\n",
      "\n",
      " bias : [0.55577405] \n",
      " bias_grad :[14.84898248]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20\n",
      "Starting forward propagation...\n",
      "Cost: 304.5942116044955\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.96973472 0.74443292 0.13059406 0.3783403  0.96866298 0.90487768\n",
      "  0.65045512 0.11790656]\n",
      " [0.46553447 0.48951735 0.9707754  0.22963673 0.65889102 0.27265575\n",
      "  0.19723403 0.47001903]\n",
      " [0.47081073 0.00436069 0.95424375 0.04260412 0.07029404 0.81390383\n",
      "  0.87151708 0.50872759]]\n",
      " weight_grad :[[34.75697593 30.71471037 13.19513123 32.25110657 26.68538009 32.68175724\n",
      "  22.17680715 46.58601018]\n",
      " [32.99868348 29.1609088  12.52761344 30.6195815  25.33541505 31.02844634\n",
      "  21.05492264 44.2293083 ]\n",
      " [32.90454065 29.07771486 12.49187308 30.53222608 25.26313496 30.93992445\n",
      "  20.99485449 44.10312532]] \n",
      "\n",
      "\n",
      " bias : [0.39742028 0.06676139 0.32312121 0.81645143 0.29751656 0.83816889\n",
      " 0.19578671 0.18296468] \n",
      " bias_grad :[57.19777359 50.54562436 21.71455106 53.07399284 43.91476208 53.78269257\n",
      " 36.4952347  76.66420887]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.46622486 0.52232043 0.67673083 0.57305817]\n",
      " [0.14256093 0.19754208 0.79945772 0.69933577]\n",
      " [0.2051273  0.12542037 0.23996405 0.23329072]\n",
      " [0.04336052 0.24648724 0.72777744 0.92045895]\n",
      " [0.45473472 0.1931782  0.67745044 0.2892775 ]\n",
      " [0.31980304 0.64128073 0.35107687 0.84435624]\n",
      " [0.69536701 0.21098145 0.40738595 0.04433696]\n",
      " [0.73975867 0.01935586 0.83828269 0.9823535 ]]\n",
      " weight_grad :[[46.96645551 18.78290104 41.6130762  47.85197188]\n",
      " [24.74470096  9.89594093 21.92422476 25.21124325]\n",
      " [46.51648232 18.60294703 41.21439232 47.39351479]\n",
      " [37.03317814 14.81036865 32.81202397 37.73141021]\n",
      " [40.21404446 16.08246586 35.63032548 40.97224931]\n",
      " [61.96733456 24.78207691 54.90410947 63.13568096]\n",
      " [37.12088061 14.84544276 32.88972985 37.82076624]\n",
      " [25.18748766 10.0730209  22.31654128 25.66237835]] \n",
      "\n",
      "\n",
      " bias : [0.65125303 0.6259115  0.41277736 0.96364543] \n",
      " bias_grad :[30.77515449 12.30764968 27.26730887 31.35539634]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.71619936 0.62679373]\n",
      " [0.26640643 0.26964882]\n",
      " [0.39394184 0.78351057]\n",
      " [0.55667769 0.80267526]]\n",
      " weight_grad :[[101.04632058 106.56552023]\n",
      " [ 86.74722282  91.48539872]\n",
      " [136.22903031 143.66992683]\n",
      " [151.86978593 160.1649882 ]] \n",
      "\n",
      "\n",
      " bias : [0.78645403 0.96655872] \n",
      " bias_grad :[22.34570822 23.56624177]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.94658124]\n",
      " [0.99828397]]\n",
      " weight_grad :[[265.44159903]\n",
      " [355.9799381 ]] \n",
      "\n",
      "\n",
      " bias : [0.5977399] \n",
      " bias_grad :[23.60675173]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21\n",
      "Starting forward propagation...\n",
      "Cost: 53.912925076335526\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.25044152 0.04077273 0.72701164 0.18734357 0.38483481 0.13405793\n",
      "  0.76844557 0.53897879]\n",
      " [0.05708161 0.1735036  0.87815484 0.80962595 0.69276642 0.78017337\n",
      "  0.56869307 0.56791792]\n",
      " [0.24215781 0.58481914 0.44754445 0.14240529 0.30819177 0.01617176\n",
      "  0.83174217 0.76031637]]\n",
      " weight_grad :[[4.12973204 2.64757272 2.95777655 4.584948   4.42024324 4.87744031\n",
      "  6.42869046 4.89053605]\n",
      " [4.33108547 2.77666048 3.10198892 4.80849641 4.63576113 5.11524977\n",
      "  6.74213425 5.12898402]\n",
      " [4.16044356 2.66726189 2.97977261 4.61904482 4.4531152  4.9137123\n",
      "  6.47649861 4.92690543]] \n",
      "\n",
      "\n",
      " bias : [0.00874275 0.40938582 0.9809537  0.26869081 0.79814492 0.89597239\n",
      " 0.91064276 0.57992546] \n",
      " bias_grad :[ 7.3481493   4.71090121  5.26285567  8.15812797  7.86506412  8.67856782\n",
      " 11.4387512   8.70186944]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.91724685 0.86833593 0.7101747  0.20769711]\n",
      " [0.41579498 0.8537628  0.96041088 0.01146918]\n",
      " [0.1307428  0.84880392 0.49984505 0.29405567]\n",
      " [0.15269565 0.54016303 0.29558322 0.90628381]\n",
      " [0.0499121  0.80073935 0.72313196 0.73275812]\n",
      " [0.75853074 0.92469093 0.60560908 0.47743277]\n",
      " [0.81474712 0.97923413 0.11253534 0.91721198]\n",
      " [0.92299158 0.64683451 0.77457594 0.51238508]]\n",
      " weight_grad :[[ 0.98130292  0.97002748  0.25914159  2.05475232]\n",
      " [ 2.6526501   2.62217041  0.70050944  5.5543898 ]\n",
      " [ 6.62035285  6.54428316  1.7482968  13.86237121]\n",
      " [ 2.85527879  2.82247085  0.75401944  5.97867447]\n",
      " [ 4.89431903  4.83808195  1.29248735 10.24822525]\n",
      " [ 4.41344557  4.36273386  1.16549872  9.24132327]\n",
      " [ 6.58389952  6.50824869  1.73867023 13.7860415 ]\n",
      " [ 5.05001817  4.99199206  1.33360423 10.57424402]] \n",
      "\n",
      "\n",
      " bias : [0.92076459 0.5736617  0.57984679 0.87139093] \n",
      " bias_grad :[3.06422483 3.02901604 0.80919772 6.41618703]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.85906448 0.29402691]\n",
      " [0.54225627 0.3258174 ]\n",
      " [0.79894647 0.0120967 ]\n",
      " [0.43290839 0.77216735]]\n",
      " weight_grad :[[ 5.76417811 50.30693898]\n",
      " [ 8.68571623 75.8047007 ]\n",
      " [ 5.8504931  51.0602542 ]\n",
      " [ 6.35255071 55.44196843]] \n",
      "\n",
      "\n",
      " bias : [0.96366457 0.31204015] \n",
      " bias_grad :[0.89461503 7.80776427]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.08900814]\n",
      " [0.77681966]]\n",
      " weight_grad :[[201.64557675]\n",
      " [109.87692994]] \n",
      "\n",
      "\n",
      " bias : [0.92515389] \n",
      " bias_grad :[10.05093551]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22\n",
      "Starting forward propagation...\n",
      "Cost: 83.61382007124983\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.0478495  0.85282426 0.4333912  0.83413263 0.87495324 0.62381266\n",
      "  0.58267992 0.96892604]\n",
      " [0.34377421 0.80645006 0.11947092 0.38269718 0.19560867 0.06009733\n",
      "  0.50518372 0.76795121]\n",
      " [0.75808316 0.45428538 0.2020106  0.29627301 0.08371749 0.16912198\n",
      "  0.2006638  0.48700517]]\n",
      " weight_grad :[[ 8.59712326  9.60465328  6.15645285 11.19311542  7.98353248  5.08749628\n",
      "   9.19144602  5.71222965]\n",
      " [ 8.03524429  8.97692555  5.75408787 10.46157117  7.46175574  4.75499469\n",
      "   8.59072413  5.33889759]\n",
      " [ 7.84760419  8.76729518  5.61971764 10.21727115  7.28750782  4.64395542\n",
      "   8.39011238  5.21422294]] \n",
      "\n",
      "\n",
      " bias : [0.39623859 0.01827183 0.52970135 0.8233302  0.3935855  0.20751999\n",
      " 0.91793229 0.85414419] \n",
      " bias_grad :[14.0814957  15.73176047 10.0838457  18.33355204 13.07647628  8.33296847\n",
      " 15.05495545  9.35623869]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[3.54328371e-01 9.14272997e-01 4.66453852e-01 1.58346397e-01]\n",
      " [7.09558769e-01 4.89582058e-01 7.51755894e-01 5.44332892e-01]\n",
      " [3.56563572e-01 2.77111825e-02 9.71808072e-01 3.30626405e-01]\n",
      " [7.99018292e-01 6.34929663e-01 6.64927416e-01 9.89873944e-01]\n",
      " [5.23274575e-01 7.63731011e-01 6.88256562e-02 7.94426051e-01]\n",
      " [3.81080726e-01 1.10548085e-01 6.00596749e-01 2.67011892e-01]\n",
      " [8.04355577e-01 7.25270175e-01 2.81535534e-01 4.45480677e-01]\n",
      " [2.70221324e-01 7.43705796e-01 3.56814539e-05 3.19385163e-01]]\n",
      " weight_grad :[[ 7.08939808  9.26921671  6.94660924  3.00356943]\n",
      " [ 8.50306788 11.11755582  8.33180606  3.60249974]\n",
      " [ 6.62058027  8.65624875  6.48723397  2.80494511]\n",
      " [11.65214406 15.23489685 11.41745613  4.93667069]\n",
      " [ 7.37420563  9.6415957   7.22568043  3.12423401]\n",
      " [ 4.86786308  6.36461337  4.76981857  2.0623704 ]\n",
      " [11.36489037 14.85931958 11.13598806  4.81496975]\n",
      " [14.63456896 19.13434535 14.33981147  6.20023639]] \n",
      "\n",
      "\n",
      " bias : [0.24230013 0.99645914 0.96307662 0.14557305] \n",
      " bias_grad :[6.78998076 8.8777358  6.65322254 2.87671512]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.93595766 0.0646019 ]\n",
      " [0.16041327 0.81644867]\n",
      " [0.30204898 0.48669915]\n",
      " [0.2628917  0.11937031]]\n",
      " weight_grad :[[39.49427779 57.37207992]\n",
      " [48.83339055 70.93871169]\n",
      " [35.97916436 52.26578655]\n",
      " [36.27641444 52.69759228]] \n",
      "\n",
      "\n",
      " bias : [0.63542743 0.14271796] \n",
      " bias_grad :[6.59347682 9.57813385]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.53074822]\n",
      " [0.77100105]]\n",
      " weight_grad :[[130.74449703]\n",
      " [122.85246022]] \n",
      "\n",
      "\n",
      " bias : [0.73068974] \n",
      " bias_grad :[12.42298422]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23\n",
      "Starting forward propagation...\n",
      "Cost: 95.34501152604373\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.09752478 0.10744221 0.29240322 0.99992104 0.73285319 0.18420426\n",
      "  0.7899883  0.22390743]\n",
      " [0.96830898 0.61618896 0.90295547 0.9002278  0.51694846 0.60344335\n",
      "  0.26975711 0.21085165]\n",
      " [0.54106616 0.10299702 0.66597676 0.92961171 0.4638849  0.96080144\n",
      "  0.784187   0.55882515]]\n",
      " weight_grad :[[ 6.69265463 11.68327492 11.0073281   6.97055961  2.52635409 11.59746632\n",
      "   7.86480982  4.72588792]\n",
      " [ 7.24667216 12.6504157  11.91851403  7.54758211  2.73548552 12.55750387\n",
      "   8.51585829  5.11709663]\n",
      " [ 7.19861215 12.566518   11.83947031  7.49752646  2.71734375 12.47422236\n",
      "   8.45938102  5.08315999]] \n",
      "\n",
      "\n",
      " bias : [0.84893156 0.77219863 0.44028125 0.48725963 0.14017045 0.271341\n",
      " 0.67228342 0.58679001] \n",
      " bias_grad :[11.9444566  20.85127322 19.64490325 12.44043677  4.50881278 20.69812964\n",
      " 14.03641525  8.43434576]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.32113923 0.59616433 0.14835674 0.53285295]\n",
      " [0.79243405 0.99615383 0.15381263 0.77711426]\n",
      " [0.56176093 0.61986025 0.55536682 0.98150904]\n",
      " [0.84717248 0.19285642 0.3307891  0.27514292]\n",
      " [0.10419676 0.03854003 0.21041671 0.29669751]\n",
      " [0.94217107 0.87962899 0.47459137 0.51556018]\n",
      " [0.90259901 0.37770042 0.28887373 0.27485799]\n",
      " [0.03939511 0.32629297 0.19303507 0.6136504 ]]\n",
      " weight_grad :[[15.81357898 12.84421059  8.2647766  14.5310505 ]\n",
      " [11.03748666  8.96494103  5.76860947 10.14231353]\n",
      " [13.51763215 10.97938134  7.06482764 12.42131181]\n",
      " [18.74471184 15.22495487  9.79669789 17.22445972]\n",
      " [ 9.95565889  8.08625167  5.20320522  9.14822522]\n",
      " [11.48476729  9.32823428  6.00237531 10.55331836]\n",
      " [15.23975654 12.3781367   7.96487522 14.00376677]\n",
      " [10.24248944  8.31922309  5.35311375  9.41179295]] \n",
      "\n",
      "\n",
      " bias : [0.86142995 0.78658844 0.42593505 0.02048162] \n",
      " bias_grad :[8.70248735 7.06839232 4.54825021 7.99668964]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.41772606 0.86345857]\n",
      " [0.44121216 0.68104641]\n",
      " [0.95433236 0.30484709]\n",
      " [0.36734574 0.79671246]]\n",
      " weight_grad :[[14.88326943 74.80941677]\n",
      " [12.3682666  62.167981  ]\n",
      " [ 7.43684123 37.38061439]\n",
      " [11.55067746 58.05844261]] \n",
      "\n",
      "\n",
      " bias : [0.75111509 0.70532891] \n",
      " bias_grad :[1.82909018 9.1937575 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.13915453]\n",
      " [0.69944777]]\n",
      " weight_grad :[[175.2607407 ]\n",
      " [244.57865181]] \n",
      "\n",
      "\n",
      " bias : [0.11821537] \n",
      " bias_grad :[13.14430892]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24\n",
      "Starting forward propagation...\n",
      "Cost: 78.68949392632419\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.166836   0.99189655 0.651457   0.53884781 0.06109225 0.06270935\n",
      "  0.7381368  0.4660113 ]\n",
      " [0.18227211 0.56862297 0.85631722 0.21556175 0.60939322 0.66713179\n",
      "  0.45943472 0.22242939]\n",
      " [0.45382479 0.53287302 0.06483122 0.03273111 0.78041221 0.29518169\n",
      "  0.8888503  0.77845542]]\n",
      " weight_grad :[[3.10204496 7.27985696 8.36685387 5.67855527 9.57906468 6.71251087\n",
      "  8.39874673 9.68162047]\n",
      " [3.12508458 7.33392617 8.42899646 5.72073124 9.65021065 6.76236627\n",
      "  8.4611262  9.75352815]\n",
      " [3.14175579 7.37305006 8.47396216 5.7512493  9.70169109 6.79844108\n",
      "  8.5062633  9.80555975]] \n",
      "\n",
      "\n",
      " bias : [0.74240881 0.957533   0.17729196 0.02863682 0.44419623 0.60315123\n",
      " 0.80837066 0.83963056] \n",
      " bias_grad :[ 5.31849455 12.48140502 14.3450747   9.73595342 16.42342516 11.50868311\n",
      " 14.39975541 16.59925834]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.15752113 0.29473777 0.02498602 0.54629762]\n",
      " [0.42289518 0.89322952 0.10600087 0.85706497]\n",
      " [0.76645669 0.84585271 0.38427069 0.42686593]\n",
      " [0.79896134 0.08035798 0.35456443 0.4472962 ]\n",
      " [0.95216363 0.65637045 0.60019667 0.54913693]\n",
      " [0.16593222 0.85557901 0.19562655 0.87100893]\n",
      " [0.75300846 0.3103174  0.93255733 0.26472468]\n",
      " [0.41703244 0.91279796 0.80120153 0.59025579]]\n",
      " weight_grad :[[ 6.9884766   7.4020555   9.11997122  5.40196838]\n",
      " [12.56852793 13.31233495 16.4019456   9.71524902]\n",
      " [ 6.32014602  6.69417304  8.24779894  4.8853607 ]\n",
      " [ 2.81240992  2.97884869  3.67019868  2.17394296]\n",
      " [ 7.47170194  7.91387817  9.75058093  5.77549299]\n",
      " [ 6.93781986  7.34840089  9.05386412  5.36281162]\n",
      " [11.69968339 12.39207209 15.26810233  9.04364761]\n",
      " [ 9.79030549 10.36969697 12.77636164  7.56773238]] \n",
      "\n",
      "\n",
      " bias : [0.70584256 0.40724888 0.20231667 0.13635614] \n",
      " bias_grad :[5.75229415 6.09271562 7.50675149 4.44642129]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.36848312 0.51335879]\n",
      " [0.08103295 0.93876026]\n",
      " [0.38899949 0.78728334]\n",
      " [0.02186659 0.73270735]]\n",
      " weight_grad :[[50.26790729 39.35413791]\n",
      " [57.9036317  45.33205439]\n",
      " [39.84089323 31.19095445]\n",
      " [49.78273632 38.97430341]] \n",
      "\n",
      "\n",
      " bias : [0.35962966 0.46793149] \n",
      " bias_grad :[7.46677347 5.84564683]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.62227734]\n",
      " [0.48717342]]\n",
      " weight_grad :[[ 68.27649647]\n",
      " [243.459432  ]] \n",
      "\n",
      "\n",
      " bias : [0.16956777] \n",
      " bias_grad :[11.99910877]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 25\n",
      "Starting forward propagation...\n",
      "Cost: 4.744457753940329\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.14258678 0.38611849 0.96234032 0.26226073 0.12140835 0.66736153\n",
      "  0.91146048 0.43367783]\n",
      " [0.49604    0.06420013 0.4007268  0.33024537 0.72081758 0.0434839\n",
      "  0.55196126 0.75667773]\n",
      " [0.30612687 0.18203862 0.38018459 0.00306673 0.91010314 0.25040429\n",
      "  0.5221656  0.373034  ]]\n",
      " weight_grad :[[0.48040173 0.67004682 0.71263831 0.5434079  0.58454011 0.53296198\n",
      "  0.42158718 0.21755925]\n",
      " [0.46191033 0.64425569 0.68520776 0.52249129 0.56204026 0.51244745\n",
      "  0.40535964 0.20918506]\n",
      " [0.45878763 0.63990026 0.68057549 0.51895904 0.55824065 0.5089831\n",
      "  0.40261925 0.20777089]] \n",
      "\n",
      "\n",
      " bias : [0.8900574  0.091857   0.2499688  0.10170267 0.65274755 0.90796243\n",
      " 0.88206337 0.94610081] \n",
      " bias_grad :[0.79953788 1.11516628 1.18605177 0.90439973 0.97285653 0.88701447\n",
      " 0.70165217 0.36208625]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.0177802  0.51521999 0.31048049 0.58277492]\n",
      " [0.30643589 0.876016   0.59730027 0.0768969 ]\n",
      " [0.84401806 0.46468771 0.89694727 0.15965025]\n",
      " [0.46124062 0.01179246 0.97435952 0.78267338]\n",
      " [0.19217499 0.64994527 0.31614385 0.50422738]\n",
      " [0.91278362 0.03458306 0.9368157  0.18966344]\n",
      " [0.08464965 0.43690546 0.68166973 0.18696554]\n",
      " [0.02300955 0.33890659 0.19644421 0.01314519]]\n",
      " weight_grad :[[0.77440288 1.20891952 0.43055356 0.65102276]\n",
      " [0.2506384  0.39127134 0.13935028 0.21070596]\n",
      " [0.68817743 1.07431307 0.38261382 0.578535  ]\n",
      " [0.24332985 0.37986198 0.13528686 0.20456183]\n",
      " [0.89632604 1.39925363 0.49834056 0.75352076]\n",
      " [0.79583121 1.24237127 0.44246731 0.66903706]\n",
      " [1.10305117 1.72197202 0.61327588 0.92730984]\n",
      " [1.0005437  1.56194771 0.55628364 0.84113416]] \n",
      "\n",
      "\n",
      " bias : [0.64377092 0.19216331 0.44063418 0.7005639 ] \n",
      " bias_grad :[0.53854118 0.84071607 0.29941885 0.45273923]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.56815898 0.20227399]\n",
      " [0.88557959 0.4356129 ]\n",
      " [0.311217   0.5200407 ]\n",
      " [0.47812909 0.12719642]]\n",
      " weight_grad :[[3.76073075 0.04307889]\n",
      " [4.33988638 0.04971307]\n",
      " [6.06366491 0.06945883]\n",
      " [3.4540471  0.03956585]] \n",
      "\n",
      "\n",
      " bias : [0.9183613  0.34885032] \n",
      " bias_grad :[0.94402073 0.01081369]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.32375307]\n",
      " [0.00370857]]\n",
      " weight_grad :[[32.07863275]\n",
      " [20.30320653]] \n",
      "\n",
      "\n",
      " bias : [0.0809355] \n",
      " bias_grad :[2.91586648]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 26\n",
      "Starting forward propagation...\n",
      "Cost: 183.45118394382834\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.71054436 0.63963821 0.09923699 0.87121247 0.67365901 0.13967289\n",
      "  0.66432892 0.2494938 ]\n",
      " [0.51671122 0.50152307 0.51488418 0.04320394 0.58253494 0.88158821\n",
      "  0.20748912 0.09305772]\n",
      " [0.38585024 0.89346604 0.47948725 0.11911456 0.40478508 0.48617524\n",
      "  0.76803637 0.51508891]]\n",
      " weight_grad :[[13.29219609 14.68737705 21.53856496 18.44710757 23.00808118 21.00972796\n",
      "  31.86550477 19.16885031]\n",
      " [12.87484917 14.22622439 20.86229946 17.86790731 22.28567597 20.35006682\n",
      "  30.86499515 18.56698885]\n",
      " [13.38176823 14.7863509  21.68370693 18.57141713 23.16312579 21.15130625\n",
      "  32.08023691 19.29802348]] \n",
      "\n",
      "\n",
      " bias : [0.10067901 0.42599161 0.85401549 0.46815832 0.658059   0.10402308\n",
      " 0.2019594  0.05149761] \n",
      " bias_grad :[22.05055092 24.36502992 35.73053093 30.60208277 38.16832541 34.85323818\n",
      " 52.86198991 31.79938867]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.41062805 0.10469039 0.38228802 0.41546113]\n",
      " [0.65533278 0.38752015 0.26172983 0.30598072]\n",
      " [0.68606309 0.42508032 0.40341809 0.7508647 ]\n",
      " [0.9961829  0.35030685 0.45233496 0.17760776]\n",
      " [0.86603573 0.04525766 0.71569353 0.61204345]\n",
      " [0.55411072 0.96272482 0.74022939 0.04589726]\n",
      " [0.93993901 0.26285163 0.95284539 0.98129561]\n",
      " [0.2467731  0.27753542 0.43518357 0.94841678]]\n",
      " weight_grad :[[15.26431537 11.92804138 22.07538397 18.11191803]\n",
      " [23.60359494 18.44463052 34.13572169 28.00691457]\n",
      " [21.58008825 16.8633954  31.20930894 25.60591679]\n",
      " [15.6368265  12.21913391 22.61411276 18.55392219]\n",
      " [23.6510672  18.48172691 34.20437648 28.06324292]\n",
      " [14.30600921 11.17918922 20.68947337 16.97483705]\n",
      " [17.05341578 13.32610367 24.66279634 20.23478034]\n",
      " [ 8.15381185  6.37165852 11.79211271  9.67492928]] \n",
      "\n",
      "\n",
      " bias : [0.51858946 0.21099564 0.13189482 0.82845514] \n",
      " bias_grad :[14.3346295  11.20155406 20.73086428 17.00879654]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.3877632  0.53423611]\n",
      " [0.24668848 0.49085857]\n",
      " [0.72503995 0.55859301]\n",
      " [0.81100984 0.17666261]]\n",
      " weight_grad :[[132.87559653 101.97592686]\n",
      " [ 62.68642427  48.10895593]\n",
      " [ 96.51589135  74.07152054]\n",
      " [105.31957499  80.82794401]] \n",
      "\n",
      "\n",
      " bias : [0.19517817 0.04683447] \n",
      " bias_grad :[17.96848822 13.7899907 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.99137082]\n",
      " [0.76083164]]\n",
      " weight_grad :[[227.85463003]\n",
      " [176.64206494]] \n",
      "\n",
      "\n",
      " bias : [0.85139881] \n",
      " bias_grad :[18.12489122]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 27\n",
      "Starting forward propagation...\n",
      "Cost: 3.1696556163488223\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.11297029 0.46138016 0.79896039 0.32136409 0.26193037 0.67915101\n",
      "  0.61048595 0.62856448]\n",
      " [0.90800647 0.04354958 0.01573847 0.02606333 0.07270641 0.82800517\n",
      "  0.36274012 0.06857042]\n",
      " [0.29721995 0.39352347 0.42875713 0.73553198 0.81977541 0.65123367\n",
      "  0.85466147 0.11786608]]\n",
      " weight_grad :[[0.30943221 0.34381812 0.28611003 0.35553822 0.36116708 0.42055414\n",
      "  0.31652688 0.34818809]\n",
      " [0.28970701 0.32190094 0.26787154 0.33287392 0.33814396 0.39374531\n",
      "  0.29634942 0.32599234]\n",
      " [0.31583559 0.35093308 0.29203078 0.36289571 0.36864105 0.42925707\n",
      "  0.32307708 0.35539348]] \n",
      "\n",
      "\n",
      " bias : [0.93802143 0.52353871 0.31616668 0.28300781 0.04905155 0.82016726\n",
      " 0.41694739 0.4648722 ] \n",
      " bias_grad :[0.51524114 0.57249773 0.47640696 0.59201307 0.60138579 0.70027226\n",
      " 0.5270546  0.57977424]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.32151464 0.90109002 0.29935302 0.19395969]\n",
      " [0.78479581 0.11455045 0.54118068 0.61977216]\n",
      " [0.16718114 0.47894423 0.52156596 0.72901674]\n",
      " [0.38878167 0.94419598 0.08590496 0.94483725]\n",
      " [0.6544951  0.83166482 0.05076003 0.67418884]\n",
      " [0.28922263 0.86098041 0.74602692 0.66843014]\n",
      " [0.65872213 0.54457379 0.24669824 0.33208687]\n",
      " [0.24697278 0.77521142 0.58531583 0.47091112]]\n",
      " weight_grad :[[0.60065625 0.52640312 0.53696772 0.24228266]\n",
      " [0.37707425 0.33046032 0.33709247 0.15209789]\n",
      " [0.3775427  0.33087087 0.33751125 0.15228685]\n",
      " [0.33294132 0.29178311 0.29763903 0.13429629]\n",
      " [0.26512348 0.23234891 0.23701201 0.10694107]\n",
      " [0.74004955 0.64856461 0.66158092 0.29850879]\n",
      " [0.53446886 0.46839781 0.47779828 0.2155851 ]\n",
      " [0.33705608 0.2953892  0.30131749 0.13595603]] \n",
      "\n",
      "\n",
      " bias : [0.62121629 0.09576853 0.10621778 0.47624127] \n",
      " bias_grad :[0.3536169  0.30990278 0.31612234 0.14263606]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.64727523 0.82862971]\n",
      " [0.65653824 0.69891726]\n",
      " [0.29605552 0.82710716]\n",
      " [0.35700422 0.30493346]]\n",
      " weight_grad :[[0.51323056 1.67981905]\n",
      " [0.75117405 2.45861526]\n",
      " [0.45890268 1.50200227]\n",
      " [0.63048327 2.0635907 ]] \n",
      "\n",
      "\n",
      " bias : [0.19618511 0.10610246] \n",
      " bias_grad :[0.10526176 0.34452491]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.04488125]\n",
      " [0.14689769]]\n",
      " weight_grad :[[26.89257748]\n",
      " [34.1628671 ]] \n",
      "\n",
      "\n",
      " bias : [0.44196679] \n",
      " bias_grad :[2.3453392]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 28\n",
      "Starting forward propagation...\n",
      "Cost: 163.4823570501716\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.05934069 0.73751283 0.27530866 0.23348618 0.14094013 0.35513158\n",
      "  0.36830888 0.35213769]\n",
      " [0.30034024 0.13426734 0.474237   0.47869461 0.8437211  0.70489695\n",
      "  0.57618627 0.73293609]\n",
      " [0.12218723 0.00394541 0.16414639 0.63003303 0.2060956  0.608676\n",
      "  0.58677692 0.17001823]]\n",
      " weight_grad :[[13.64148741 13.55130265 19.90305831 11.87354303 26.29887597 20.19241776\n",
      "  15.8681276  17.03666243]\n",
      " [14.98144664 14.88240332 21.85807142 13.03984279 28.88212958 22.17585371\n",
      "  17.4268025  18.71011872]\n",
      " [13.66337918 13.57304968 19.9349986  11.89259761 26.34108022 20.22482241\n",
      "  15.89359266 17.06400274]] \n",
      "\n",
      "\n",
      " bias : [0.01525511 0.11838132 0.12509499 0.51129836 0.62287564 0.75392844\n",
      " 0.61291405 0.90243595] \n",
      " bias_grad :[24.28259983 24.12206598 35.42854132 21.13556134 46.81344944 35.94361709\n",
      " 28.24614216 30.32619858]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.62948974 0.43710989 0.53545497 0.08270309]\n",
      " [0.1953043  0.64164662 0.21028446 0.54613648]\n",
      " [0.14577775 0.9266507  0.95197007 0.28225613]\n",
      " [0.11259344 0.14454672 0.1270888  0.88193161]\n",
      " [0.6830925  0.70504477 0.89186145 0.7693479 ]\n",
      " [0.71810368 0.35580881 0.51790314 0.75480663]\n",
      " [0.19567219 0.12298822 0.73577339 0.64396532]\n",
      " [0.20740505 0.82554723 0.21290643 0.74987365]]\n",
      " weight_grad :[[ 3.75843711  3.93933959  5.26108837  5.36924077]\n",
      " [ 7.67178659  8.04104786 10.73902424 10.9597868 ]\n",
      " [ 8.25480961  8.65213316 11.55514422 11.79268378]\n",
      " [16.04885932 16.82132896 22.46531329 22.92713364]\n",
      " [16.62325494 17.4233716  23.26935658 23.74770568]\n",
      " [21.49458548 22.52917082 30.08828149 30.70680751]\n",
      " [18.69610601 19.5959939  26.17094901 26.70894626]\n",
      " [20.46755552 21.45270747 28.65063727 29.23960958]] \n",
      "\n",
      "\n",
      " bias : [0.24961349 0.99678529 0.81029483 0.2483336 ] \n",
      " bias_grad :[12.41872867 13.01647151 17.38382925 17.74118933]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.73180902 0.50768892]\n",
      " [0.1818588  0.91933109]\n",
      " [0.59320006 0.99598357]\n",
      " [0.76134664 0.9132655 ]]\n",
      " weight_grad :[[29.79750631 45.03217525]\n",
      " [45.01323879 68.02730528]\n",
      " [45.13347782 68.2090193 ]\n",
      " [53.67988631 81.12497814]] \n",
      "\n",
      "\n",
      " bias : [0.22798107 0.48648466] \n",
      " bias_grad :[ 8.2843123  12.51985986]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.47755987]\n",
      " [0.72172348]]\n",
      " weight_grad :[[208.39897282]\n",
      " [323.55380726]] \n",
      "\n",
      "\n",
      " bias : [0.13540731] \n",
      " bias_grad :[17.34717002]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 29\n",
      "Starting forward propagation...\n",
      "Cost: 79.21912105438939\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.11715836 0.64080343 0.73979926 0.05000296 0.89970806 0.48542388\n",
      "  0.05344067 0.24546729]\n",
      " [0.50310322 0.91287454 0.31586754 0.25626729 0.48769384 0.34930052\n",
      "  0.65927664 0.13250495]\n",
      " [0.15552436 0.43515199 0.23799472 0.21939882 0.20526539 0.0348269\n",
      "  0.04607358 0.04190666]]\n",
      " weight_grad :[[11.25787318 12.69743283 10.99483894  7.28210521 14.92188966  6.69524331\n",
      "   5.53831524  9.68920035]\n",
      " [11.2494783  12.68796448 10.98664021  7.27667502 14.91076256  6.69025073\n",
      "   5.53418537  9.68197521]\n",
      " [10.09748237 11.38866125  9.86156005  6.53151157 13.38383505  6.0051397\n",
      "   4.96746051  8.69049847]] \n",
      "\n",
      "\n",
      " bias : [0.01695453 0.14357561 0.86000164 0.63302338 0.54915564 0.39088342\n",
      " 0.38351939 0.08229062] \n",
      " bias_grad :[18.55458235 20.92718219 18.12106438 12.00194909 24.59340464 11.03471689\n",
      "  9.12793425 15.96918556]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.02273489 0.86452781 0.99993717 0.44354317]\n",
      " [0.9686356  0.12027605 0.69110202 0.36166807]\n",
      " [0.53769814 0.51572055 0.61851647 0.55454364]\n",
      " [0.57518834 0.36577255 0.20348878 0.37186933]\n",
      " [0.80884427 0.62928505 0.95171319 0.26038867]\n",
      " [0.42913674 0.64559071 0.21366021 0.12461023]\n",
      " [0.1463616  0.00921899 0.31574315 0.95938286]\n",
      " [0.8319109  0.2740036  0.2377251  0.69728507]]\n",
      " weight_grad :[[ 5.18036721  2.44197757  5.83125717  1.81215294]\n",
      " [14.34331842  6.76130868 16.1454922   5.01746026]\n",
      " [17.67509502  8.33187759 19.89589161  6.18295461]\n",
      " [10.17340363  4.79564911 11.45164626  3.55877537]\n",
      " [16.2929111   7.68032877 18.34004247  5.69945054]\n",
      " [ 9.9349294   4.68323455 11.18320881  3.4753543 ]\n",
      " [ 9.11715118  4.2977414  10.26268043  3.18928594]\n",
      " [ 3.62599819  1.70926227  4.08158864  1.26841651]] \n",
      "\n",
      "\n",
      " bias : [0.38870966 0.06658314 0.66586721 0.17172657] \n",
      " bias_grad :[10.84431194  5.11190913 12.2068512   3.79346693]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.46983222 0.88036257]\n",
      " [0.5553052  0.01517835]\n",
      " [0.93686776 0.5023259 ]\n",
      " [0.38797143 0.04014139]]\n",
      " weight_grad :[[45.95801311 38.37308262]\n",
      " [31.12850005 25.99103886]\n",
      " [47.04597633 39.28148792]\n",
      " [32.93881559 27.50257913]] \n",
      "\n",
      "\n",
      " bias : [0.70755447 0.17048818] \n",
      " bias_grad :[9.00018066 7.51478692]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.75003367]\n",
      " [0.62624779]]\n",
      " weight_grad :[[136.12944649]\n",
      " [ 89.89095127]] \n",
      "\n",
      "\n",
      " bias : [0.48271322] \n",
      " bias_grad :[11.99970212]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 30\n",
      "Starting forward propagation...\n",
      "Cost: 2.5467628750341866\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[0.46668166 0.19741157 0.31362709 0.67372839 0.28756671 0.70153058\n",
      "  0.15727568 0.899794  ]\n",
      " [0.21307918 0.86238237 0.9941999  0.98661758 0.96590825 0.14442976\n",
      "  0.3761429  0.34823362]\n",
      " [0.19816642 0.56358853 0.17177696 0.73223414 0.39946553 0.54458097\n",
      "  0.31921374 0.25000576]]\n",
      " weight_grad :[[0.12609366 0.26825676 0.24318912 0.13160063 0.22692985 0.19447538\n",
      "  0.20056736 0.1987983 ]\n",
      " [0.13331784 0.28362578 0.25712196 0.13914031 0.23993116 0.2056173\n",
      "  0.2120583  0.21018789]\n",
      " [0.12469946 0.26529068 0.24050022 0.13014554 0.22442072 0.19232509\n",
      "  0.19834971 0.19660021]] \n",
      "\n",
      "\n",
      " bias : [0.20432007 0.33990022 0.29368091 0.08051608 0.47669619 0.52163739\n",
      " 0.8864867  0.59622131] \n",
      " bias_grad :[0.22229317 0.4729155  0.42872324 0.23200152 0.40005943 0.34284475\n",
      " 0.35358443 0.35046571]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.15182613 0.54340817 0.74875867 0.19454333]\n",
      " [0.21534005 0.94225947 0.04278762 0.96460531]\n",
      " [0.95200652 0.19994226 0.48892191 0.69456285]\n",
      " [0.66862388 0.06867269 0.16905481 0.27674306]\n",
      " [0.61377346 0.74921767 0.78594817 0.32093783]\n",
      " [0.05242415 0.46388085 0.75312091 0.90674703]\n",
      " [0.31753923 0.31319456 0.52231992 0.87376301]\n",
      " [0.33892874 0.33919889 0.50782922 0.81546361]]\n",
      " weight_grad :[[0.15777303 0.15535639 0.02412396 0.15905988]\n",
      " [0.28640791 0.28202094 0.04379261 0.28874395]\n",
      " [0.25943598 0.25546215 0.03966852 0.26155203]\n",
      " [0.326501   0.32149992 0.04992296 0.32916405]\n",
      " [0.32160751 0.31668138 0.04917473 0.32423065]\n",
      " [0.2923015  0.28782425 0.04469375 0.2946856 ]\n",
      " [0.30760406 0.30289243 0.04703356 0.31011298]\n",
      " [0.32439741 0.31942854 0.04960131 0.3270433 ]] \n",
      "\n",
      "\n",
      " bias : [0.92362508 0.67375904 0.59044774 0.18301981] \n",
      " bias_grad :[0.22284398 0.21943063 0.0340735  0.22466157]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 3 \n",
      "\n",
      " weight : [[0.53655238 0.63937241]\n",
      " [0.53328962 0.62002591]\n",
      " [0.08237235 0.09712206]\n",
      " [0.35891057 0.99546195]]\n",
      " weight_grad :[[1.35573056 0.7032926 ]\n",
      " [1.3394661  0.69485532]\n",
      " [1.43086263 0.74226777]\n",
      " [1.75053497 0.90809953]] \n",
      "\n",
      "\n",
      " bias : [0.83866418 0.34091309] \n",
      " bias_grad :[0.2566646  0.13314616]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 4 \n",
      "\n",
      " weight : [[0.12079068]\n",
      " [0.06266082]]\n",
      " weight_grad :[[19.89514672]\n",
      " [30.35317012]] \n",
      "\n",
      "\n",
      " bias : [0.75339089] \n",
      " bias_grad :[2.12487095]\n",
      "\n",
      "\n",
      "\n",
      "1.524595466451232\n",
      "102.91018695277324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5494086991972018\n",
      "40.78872132748404\n",
      "473.97081109860267\n",
      "83.4325048371735\n",
      "41.826137792385765\n",
      "21.621859595522064\n",
      "124.97837926917958\n",
      "30.8264969491168\n",
      "78.2129161539688\n",
      "32.155331873288695\n",
      "402.2042157041353\n",
      "220.42967698016633\n",
      "16.78960741521841\n",
      "67.62320527260033\n",
      "73.0794746900715\n",
      "14.83844268004285\n",
      "122.61582842729369\n",
      "304.5942116044955\n",
      "53.912925076335526\n",
      "83.61382007124983\n",
      "95.34501152604373\n",
      "78.68949392632419\n",
      "4.744457753940329\n",
      "183.45118394382834\n",
      "3.1696556163488223\n",
      "163.4823570501716\n",
      "79.21912105438939\n",
      "2.5467628750341866\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "\n",
    "Y = np.sum(X, axis=1) % 2  \n",
    "train_iterations=30\n",
    "\n",
    "# wt,bias,layers,cost_history=MLP(np.random.rand(10,3),[1,2,3,4,5,6,7,8,9,10],[4,2,1],100,0.01,0.5)\n",
    "wt, bias, layers, cost_history = MLP(X, Y, [8,4,2,1], iterations=train_iterations, learning_rate=0.01, error_margin=0.01)\n",
    "\n",
    "for i in cost_history:\n",
    "    print(i)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([i for i in range(train_iterations)],cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing Values using trained MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting forward propagation...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[3.12200493]])]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, _, i ,_=forward_propagation(X=[1,0,1],Weights=wt,Biases=bias,Layers=[4,2,1])\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.rand?\n",
    "# np.maximum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical Evaluation\n",
    "\n",
    "Following aspects will be added in the future:\n",
    "1) Regularization to avoid overfitting\n",
    "2) Cross validation for overfitting training set\n",
    "3) Adam optimizer for momentum during learning\n",
    "4) Adapt Batch processing instead of using whole training set each iteration\n",
    "5) Class based approach for building model making the code easier and intuitive\n",
    "6) Option to use various activation functions besides ReLU\n",
    "7) Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
